{
    "docs": [
        {
            "location": "/", 
            "text": "libStorage\n\n\nOpening up storage for all\n\n\n\n\nOverview\n\n\nlibStorage\n is an open source, platform agnostic, storage provisioning and\norchestration framework, model, and API.\n\n\nFeatures\n\n\nThe following features unique to this project make it a perfect choice for\nadding value to upstream applications by centralizing storage management:\n\n\n\n\nA standardized storage orchestration \nmodel and API\n\n\nA lightweight, reference client implementation with a minimal dependency\n  footprint\n\n\nThe ability to embed both the libStorage client and server, creating native\n  application integration opportunities\n\n\n\n\nOperations\n\n\nlibStorage\n supports the following operations:\n\n\n\n\n\n\n\n\nResource Type\n\n\nOperation\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVolume\n\n\nList / Inspect\n\n\nGet detailed information about one to many volumes\n\n\n\n\n\n\n\n\nCreate / Remote\n\n\nManage the volume lifecycle\n\n\n\n\n\n\n\n\nAttach / Detach\n\n\nProvision volumes to a client\n\n\n\n\n\n\n\n\nMount / Unmount\n\n\nMake attached volumes ready-to-use, local file systems\n\n\n\n\n\n\nSnapshot\n\n\n\n\nComing soon\n\n\n\n\n\n\nStorage Pool\n\n\n\n\nComing soon\n\n\n\n\n\n\n\n\nGetting Started\n\n\nUsing libStorage can be broken down into several, distinct steps:\n\n\n\n\nConfiguring \nlibStorage\n\n\nUnderstanding the \nAPI\n\n\nIdentifying a production server and client implementation, such as\n   \nREX-Ray\n\n\n\n\nGetting Help\n\n\nTo get help with libStorage, please use the\n\ndiscussion group\n,\n\nGitHub issues\n, or tagging\nquestions with \nEMC\n at \nStackOverflow\n.\n\n\nThe code and documentation are released with no warranties or SLAs and are\nintended to be supported through a community driven process.", 
            "title": "Home"
        }, 
        {
            "location": "/#libstorage", 
            "text": "Opening up storage for all", 
            "title": "libStorage"
        }, 
        {
            "location": "/#overview", 
            "text": "libStorage  is an open source, platform agnostic, storage provisioning and\norchestration framework, model, and API.", 
            "title": "Overview"
        }, 
        {
            "location": "/#features", 
            "text": "The following features unique to this project make it a perfect choice for\nadding value to upstream applications by centralizing storage management:   A standardized storage orchestration  model and API  A lightweight, reference client implementation with a minimal dependency\n  footprint  The ability to embed both the libStorage client and server, creating native\n  application integration opportunities", 
            "title": "Features"
        }, 
        {
            "location": "/#operations", 
            "text": "libStorage  supports the following operations:     Resource Type  Operation  Description      Volume  List / Inspect  Get detailed information about one to many volumes     Create / Remote  Manage the volume lifecycle     Attach / Detach  Provision volumes to a client     Mount / Unmount  Make attached volumes ready-to-use, local file systems    Snapshot   Coming soon    Storage Pool   Coming soon", 
            "title": "Operations"
        }, 
        {
            "location": "/#getting-started", 
            "text": "Using libStorage can be broken down into several, distinct steps:   Configuring  libStorage  Understanding the  API  Identifying a production server and client implementation, such as\n    REX-Ray", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#getting-help", 
            "text": "To get help with libStorage, please use the discussion group , GitHub issues , or tagging\nquestions with  EMC  at  StackOverflow .  The code and documentation are released with no warranties or SLAs and are\nintended to be supported through a community driven process.", 
            "title": "Getting Help"
        }, 
        {
            "location": "/user-guide/config/", 
            "text": "Configuring libStorage\n\n\nTweak this, turn that, peek behind the curtain...\n\n\n\n\nOverview\n\n\nThis page reviews how to configure \nlibStorage\n to suit any environment,\nbeginning with the the most common use cases, exploring recommended guidelines,\nand finally, delving into the details of more advanced settings.\n\n\nClient/Server Configuration\n\n\nExcept when specified otherwise, the configuration examples below assume the\n\nlibStorage\n client and server exist on the same host. However, that is not at\nall a requirement. It is fully possible, and in fact the entire purpose of\n\nlibStorage\n, that the client and server be able to function on different\nsystems. One \nlibStorage\n server should be able to support hundreds of clients.\nYet for the sake of completeness, the examples below show both configurations\nmerged.\n\n\nWhen configuring a \nlibStorage\n client and server for different systems, there\nwill be a few differences from the examples below:\n\n\n\n\n\n\nThe examples show \nlibStorage\n configured with its server component hosted\n    on a UNIX socket. This is ideal for when the client/server exist on the same\n    host as it reduces security risks. However, in most real-world scenarios\n    the client and server are \nnot\n residing on the same host, the\n    \nlibStorage\n  server should use a TCP endpoint so it can be accessed\n    remotely.\n\n\n\n\n\n\nIn a distributed configuration the actual driver configuration sections\n    need only occur on the server-side. The entire purpose of \nlibStorage\n's\n    distributed nature is to enable clients without any knowledge of how to\n    access a storage platform the ability to connect to a remote server that\n    maintains that storage platform access information.\n\n\n\n\n\n\nBasic Configuration\n\n\nThis section outlines the most common configuration scenarios encountered by\n\nlibStorage\n's users.\n\n\nSimple\n\n\nThe first example is a simple \nlibStorage\n configuration with the VirtualBox\nstorage driver. The below example omits the host property, but the configuration\nis still valid. If the \nlibstorage.host\n property is not found, the server is\nhosted via a temporary UNIX socket file in \n/var/run/libstorage\n.\n\n\n\n\nnote\n\n\nPlease remember to replace the placeholders in the following examples\nwith values valid for the systems on which the examples are executed.\n\n\nThe example below specifies the \nvolumePath\n property as\n\n$HOME/VirtualBox/Volumes\n. While the text \n$HOME\n will be replaced with\nthe actual value for that environment variable at runtime, the path may\nstill be invalid. The \nvolumePath\n property should reflect a path on the\nsystem on which the VirtualBox server is running, and that is not always\nthe same system on which the \nlibStorage\n server is running.\n\n\nSo please, make sure to update the \nvolumePath\n property for the VirtualBox\ndriver to a path valid on the system on which the VirtualBox server is\nrunning.\n\n\nThe same goes for VirtualBox property \nendpoint\n as the VirtualBox\nweb service is not always available at \n10.0.2.2:18083\n.\n\n\n\n\nlibstorage:\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nTCP\n\n\nThe following example illustrates how to configure a \nlibStorage\n client and\nserver running on the same host. The server has one endpoint on which it is\naccessible - a single TCP port, 7979, bound to the localhost network interface.\n\n\nlibstorage:\n  host: tcp://127.0.0.1:7979\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nTCP+TLS\n\n\nThe following example illustrates how to configure a \nlibStorage\n client and\nserver running on the same host. The server has one endpoint on which it is\naccessible - a single TCP port, 7979, bound to all of the host's network\ninterfaces. This means that the server is accessible via external clients, not\njust those running on the same host.\n\n\nBecause of the public nature of this \nlibStorage\n server, it is a good idea to\nencrypt communications between client and server.\n\n\nlibstorage:\n  host: tcp://127.0.0.1:7979\n  client:\n    tls:\n      certFile: $HOME/.libstorage/libstorage-client.crt\n      keyFile: $HOME/.libstorage/libstorage-client.key\n      trustedCertsFile: $HOME/.libstorage/trusted-certs.crt\n  server:\n    tls:\n      certFile: /etc/libstorage/libstorage-server.crt\n      keyFile: /etc/libstorage/libstorage-server.key\n      trustedCertsFile: /etc/libstorage/trusted-certs.crt\n      clientCertRequired: true\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nPlease note that in the above example the property \nlibstorage.client\n has been\nintroduced. This property is always present, even if not explicitly specified.\nIt exists to override \nlibStorage\n properties for the client only, such as TLS\nsettings, logging, etc.\n\n\nUNIX Socket\n\n\nFor the security conscious, there is no safer way to run a client/server setup\non a single system than the option to use a UNIX socket. The socket offloads\nauthentication and relies on the file system file access to ensure authorized\nusers can use the \nlibStorage\n API.\n\n\nlibstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nIt is possible to apply TLS to the UNIX socket. Refer to the TCP+TLS section\nfor applying TLS to the UNIX sockets.\n\n\nMultiple Endpoints\n\n\nThere may be occasions when it is desirable to provide multiple ingress vectors\nfor the \nlibStorage\n API. In these situations, configuring multiple endpoints\nis the solution. The below example illustrates how to configure three endpoints:\n\n\n\n\n\n\n\n\nendpoint\n\n\nprotocol\n\n\naddress\n\n\ntls\n\n\nlocalhost only\n\n\n\n\n\n\n\n\n\n\nsock\n\n\nunix socket\n\n\n/var/run/libstorage/localhost.sock\n\n\nno\n\n\nyes\n\n\n\n\n\n\nprivate\n\n\ntcp\n\n\n127.0.0.1:7979\n\n\nno\n\n\nyes\n\n\n\n\n\n\npublic\n\n\ntcp\n\n\n*:7980\n\n\nyes\n\n\nno\n\n\n\n\n\n\n\n\nlibstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n    endpoints:\n      sock:\n        address: unix:///var/run/libstorage/localhost.sock\n      private:\n        address: tcp://127.0.0.1:7979\n      public:\n        address: tcp://:7980\n        tls:\n          certFile: /etc/libstorage/libstorage-server.crt\n          keyFile: /etc/libstorage/libstorage-server.key\n          trustedCertsFile: /etc/libstorage/trusted-certs.crt\n          clientCertRequired: true\n\n\n\n\nWith all three endpoints defined explicitly in the above example, why leave the\nproperty \nlibstorage.host\n in the configuration at all? When there are no\nendpoints defined, the \nlibStorage\n server will attempt to create a default\nendpoint using the value from the property \nlibstorage.host\n. However, even\nwhen there's at least one explicitly defined endpoint, the \nlibstorage.host\n\nproperty still serves a very important function -- it is the property used\nby the \nlibStorage\n client to determine which to which endpoint to connect.\n\n\nMultiple Services\n\n\nAll of the previous examples have used the VirtualBox storage driver as the\nsole measure of how to configure a \nlibStorage\n service. However, it is possible\nto configure many services at the same time in order to provide access to\nmultiple storage drivers of different types, or even different configurations\nof the same driver.\n\n\nThe following example demonstrates how to configure three \nlibStorage\n services:\n\n\n\n\n\n\n\n\nservice\n\n\ndriver\n\n\n\n\n\n\n\n\n\n\nvirtualbox-00\n\n\nvirtualbox\n\n\n\n\n\n\nvirtualbox-01\n\n\nvirtualbox\n\n\n\n\n\n\nscaleio\n\n\nscaleio\n\n\n\n\n\n\n\n\nNotice how the \nvirtualbox-01\n service includes an added \nintegration\n section.\nThe integration definition refers to the integration interface and parameters\nspecific to incoming requests through this layer. In this case we defined\n\nlibstorage.server.services.virtualbox-01\n with the\n\nintegration.volume.operations.create.default.size\n parameter set. This enables all\ncreate requests that come in through \nvirtualbox-01\n to have a default size of\n1GB. So although it is technically the same platform below the covers,\n\nvirtualbox-00\n requests may have different default values than those defined\nin \nvirtualbox-01\n.\n\n\nlibstorage:\n  server:\n    services:\n      virtualbox-00:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes-00\n          controllerName: SATA\n      virtualbox-01:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes-01\n          controllerName: SATA\n        integration:\n          volume:\n            operations:\n              create:\n                default:\n                  size: 1 # GB\n      scaleio:\n        driver: scaleio\n        scaleio:\n          endpoint: https://gateway_ip/api\n          insecure: true\n          userName: username\n          password: password\n          systemName: tenantName\n          protectionDomainName: protectionDomainName\n          storagePoolName: storagePoolName\n\n\n\n\nA very important point to make about the relationship between services and\nendpoints is that all configured services are available on all endpoints. In\nthe future this may change, and \nlibStorage\n may support endpoint-specific\nservice definitions, but for now if a service is configured, it is accessible\nvia any of the available endpoint addresses.\n\n\nBetween the three services above, clearly one major difference is that two\nservices host one driver, VirtualBox, and the third service hosts ScaleIO.\nHowever, why two services for one driver, in this case, VirtualBox? Because,\nin addition to services being configured to host different types of drivers,\nservices can also host different driver configurations. In service\n\nvirtualbox-00\n, the volume path is \n$HOME/VirtualBox/Volumes-00\n,\nwhereas for service \nvirtualbox-01\n, the volume path is\n\n$HOME/VirtualBox/Volumes-01\n.\n\n\nLogging\n\n\nSometimes it helps to see a little more, or maybe even a little less,\ninformation in the logs. Configuring logging is quite straight-forward:\n\n\nlibstorage:\n  logging:\n    level: warn\n  server:\n    logging:\n      level: info\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nThe \nlibStorage\n configuration shown above uses a global log level of \nwarn\n,\nand a more verbose, \ninfo\n log level for just the server.\n\n\nAdvanced Configuration\n\n\nThe following sections detail every last aspect of how \nlibStorage\n works and can\nbe configured.\n\n\nEmbedded Configuration\n\n\nIf \nlibStorage\n is embedded into another application, such as\n\nREX-Ray\n, then that application may\nmanage its own configuration and supply the embedded \nlibStorage\n instance\ndirectly with a configuration object. In this scenario, the \nlibStorage\n\nconfiguration files are ignored in deference to the embedding application.\n\n\nData Directories\n\n\nThe first time \nlibStorage\n is executed it will create several directories if\nthey do not already exist:\n\n\n\n\n/etc/libstorage\n\n\n/var/log/libstorage\n\n\n/var/run/libstorage\n\n\n/var/lib/libstorage\n\n\n\n\nThe above directories will contain configuration files, logs, PID files, and\nmounted volumes. However, the location of these directories can also be\ninfluenced with the environment variable \nLIBSTORAGE_HOME\n. All of the above\ndata directories will be placed in their same paths, but prefixed by the path\nspecified via \nLIBSTORAGE_HOME\n, if \nLIBSTORAGE_HOME\n is in fact specified.\n\n\nConfiguration Methods\n\n\nThere are three ways to configure \nlibStorage\n:\n\n\n\n\nCommand line options\n\n\nEnvironment variables\n\n\nConfiguration files\n\n\n\n\nThe order of the items above is also the order of precedence when considering\noptions set in multiple locations that may override one another. Values set\nvia CLI flags have the highest order of precedence, followed by values set by\nenvironment variables, followed, finally, by values set in configuration files.\n\n\nConfiguration Files\n\n\nThere are two \nlibStorage\n configuration files - global and user:\n\n\n\n\n/etc/libstorage/config.yml\n\n\n$HOME/.libstorage/config.yml\n\n\n\n\nPlease note that while the user configuration file is located inside the user's\nhome directory, this is the directory of the user that starts \nlibStorage\n. And\nif \nlibStorage\n is being started as a service, then \nsudo\n is likely being used,\nwhich means that \n$HOME/.libstorage/config.yml\n won't point to \nyour\n home\ndirectory, but rather \n/root/.libstorage/config.yml\n.\n\n\nConfiguration Properties\n\n\nThe section \nConfiguration Methods\n mentions there are\nthree ways to configure libStorage: config files, environment variables, and the\ncommand line. However, this section will illuminate the relationship between the\nnames of the configuration file properties, environment variables, and CLI\nflags.\n\n\nBelow is a simple configuration file that tells the \nlibStorage\n client where\nthe \nlibStorage\n server is hosted:\n\n\nlibstorage:\n  host: tcp://192.168.0.20:7979\n\n\n\n\nThe property \nlibstorage.host\n is a string. This value can also be set via\nenvironment variables or the command line, but to do so requires knowing the\nnames of the environment variables or CLI flags to use. Luckily those are very\neasy to figure out just by knowing the property names.\n\n\nAll properties that might appear in the \nlibStorage\n configuration file\nfall under some type of heading. For example, take the default configuration\nabove.\n\n\nThe rule for environment variables is as follows:\n\n\n\n\nEach nested level becomes a part of the environment variable name followed\n    by an underscore \n_\n except for the terminating part.\n\n\nThe entire environment variable name is uppercase.\n\n\n\n\nNested properties follow these rules for CLI flags:\n\n\n\n\nThe root level's first character is lower-cased with the rest of the root\n    level's text left unaltered.\n\n\nThe remaining levels' first characters are all upper-cased with the the\n    remaining text of that level left unaltered.\n\n\nAll levels are then concatenated together.\n\n\n\n\nThe following example builds on the previous. In this case we have added logging\ndirectives to the client instance and reference how their transformation in\nthe table below the example.\n\n\n  libstorage:\n    host: tcp://192.168.0.20:7979\n    logging:\n      level: warn\n      stdout:\n      stderr:\n      httpRequests: false\n      httpResponses: false\n\n\n\n\nThe following table illustrates the transformations:\n\n\n\n\n\n\n\n\nProperty Name\n\n\nEnvironment Variable\n\n\nCLI Flag\n\n\n\n\n\n\n\n\n\n\nlibstorage.host\n\n\nLIBSTORAGE_HOST\n\n\n--libstorageHost\n\n\n\n\n\n\nlibstorage.logging.level\n\n\nLIBSTORAGE_LOGGING_LEVEL\n\n\n--libstorageLoggingLevel\n\n\n\n\n\n\nlibstorage.logging.stdout\n\n\nLIBSTORAGE_LOGGING_STDOUT\n\n\n--libstorageLoggingStdout\n\n\n\n\n\n\nlibstorage.logging.stderr\n\n\nLIBSTORAGE_LOGGING_STDERR\n\n\n--libstorageLoggingStderr\n\n\n\n\n\n\nlibstorage.logging.httpRequests\n\n\nLIBSTORAGE_LOGGING_HTTPREQUESTS\n\n\n--libstorageLoggingHttpRequests\n\n\n\n\n\n\nlibstorage.logging.httpResponses\n\n\nLIBSTORAGE_LOGGING_HTTPRESPONSES\n\n\n--libstorageLoggingHttpResponses\n\n\n\n\n\n\n\n\nInherited Properties\n\n\nReferring to the section on defining\n\nMultiple Services\n, there is also another way\nto define the TLS settings for the external TCP endpoint. The same configuration\ncan be rewritten and simplified in the process:\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        create:\n          default:\n            size: 1 # GB\n  server:\n    virtualbox:\n      endpoint:       http://10.0.2.2:18083\n      tls:            false\n      controllerName: SATA\n    services:\n      virtualbox-00:\n        driver: virtualbox\n        virtualbox:\n          volumePath: $HOME/VirtualBox/Volumes-00\n      virtualbox-01:\n        driver: virtualbox\n        virtualbox:\n          volumePath: $HOME/VirtualBox/Volumes-01\n\n\n\n\nThe above example may look different than the previous one, but it's actually\nthe same with a minor tweak in order to simplify configuration.\n\n\nWhile there are still two VirtualBox services defined, \nvirtualbox-00\n and\n\nvirtualbox-01\n, neither service contains configuration information about the\nVirtualBox driver other than the \nvolumePath\n property. This is because the\nchange affected above is to take advantage of inherited properties.\n\n\nWhen a property is omitted, \nlibStorage\n traverses the configuration instance\nupwards, checking certain, predefined levels known as \"scopes\" to see if the\nproperty value exists there. All configured services represent a valid\nconfiguration scope as does \nlibstorage.server\n.\n\n\nThus when the VirtualBox driver is initialized and it checks for its properties,\nwhile the driver may only find the \nvolumePath\n property defined under the\nconfigured service scope, the property access attempt travels up the\nconfiguration stack until it hits the \nlibstorage.server\n scope where the\nremainder of the VirtualBox driver's properties \nare\n defined.\n\n\nOverriding Inherited Properties\n\n\nIt's also possible to override inherited properties as is demonstrated in the\n\nLogging configuration example\n above:\n\n\nlibstorage:\n  logging:\n    level: warn\n  integration:\n    volume:\n      operations:\n        create:\n          default:\n            size: 1 # GB\n  server:\n    logging:\n      level: info\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nNote that while the log level is defined at the root of the config, it's also\ndefined at \nlibstorage.server.logging.level\n. The latter value of \ninfo\n\noverrides the former value of \nwarn\n. Also please remember that even had the\nlatter, server-specific value of \ninfo\n not been defined, an attempt by to\naccess the log level by the server would be perfectly valid since the attempt\nwould traverse up the configuration data until it found the log level defined\nat the root of the configuration.\n\n\nLogging Configuration\n\n\nThe \nlibStorage\n log level determines the level of verbosity emitted by the\ninternal logger. The default level is \nwarn\n, but there are three other levels\nas well:\n\n\n\n\n\n\n\n\nLog Level\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nerror\n\n\nLog only errors\n\n\n\n\n\n\nwarn\n\n\nLog errors and anything out of place\n\n\n\n\n\n\ninfo\n\n\nLog errors, warnings, and workflow messages\n\n\n\n\n\n\ndebug\n\n\nLog everything\n\n\n\n\n\n\n\n\nTasks Configuration\n\n\nAll operations received by the libStorage API are immediately enqueued into a\nTask Service in order to divorce the business objective from the scope of the\nHTTP request that delivered it. If a task completes before the HTTP request\ntimes out, the result of the task is written to the HTTP response and sent to\nthe client. However, if the operation is long-lived and continues to execute\nafter the original HTTP request has timed out, the goroutine running the\noperation will finish regardless.\n\n\nIn the case of such a timeout event, the client receives an HTTP status 408 -\nRequest Timeout. The HTTP response body also includes the task ID which can\nbe used to monitor the state of the remote call. The following resource URI can\nbe used to retrieve information about a task:\n\n\nGET /tasks/${taskID}\n\n\n\n\nFor systems that experience heavy loads the task system can also be a source of\npotential resource issues. Because tasks are kept indefinitely at this point in\ntime, too many tasks over a long period of time can result in a massive memory\nconsumption, with reports of up to 50GB and more.\n\n\nThat's why the configuration property \nlibstorage.server.tasks.logTimeout\n is\navailable to adjust how long a task is logged before it is removed from memory.\nThe default value is \n0\n -- that is, do not log the task in memory at all.\n\n\nWhile this is in contradiction to the task retrieval example above --\nobviously a task cannot be retrieved if it is not retained -- testing and\nbenchmarks have shown it is too dangerous to enable task retention by default.\nInstead tasks are removed immediately upon completion.\n\n\nThe follow configuration example illustrates a libStorage server that keeps\ntasks logged for 10 minutes before purging them from memory:\n\n\nlibstorage:\n  server:\n    tasks:\n      logTimeout: 10m\n\n\n\n\nThe \nlibstorage.server.tasks.logTimeout\n property can be set to any value that\nis parseable by the Golang\n\ntime.ParseDuration\n function. For\nexample, \n1000ms\n, \n10s\n, \n5m\n, and \n1h\n are all valid values.\n\n\nDriver Configuration\n\n\nThere are three types of drivers:\n\n\n\n\nOS Drivers\n\n\nStorage Drivers\n\n\nIntegration Drivers\n\n\n\n\nOS Drivers\n\n\nOperating system (OS) drivers enable \nlibStorage\n to manage storage on\nthe underlying OS. Currently the following OS drivers are supported:\n\n\n\n\n\n\n\n\nDriver\n\n\nDriver Name\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\nlinux\n\n\n\n\n\n\n\n\nThe OS driver \nlinux\n is automatically activated when \nlibStorage\n is running on\nthe Linux OS.\n\n\nStorage Drivers\n\n\nStorage drivers enable \nlibStorage\n to communicate with direct-attached or\nremote storage systems. Currently the following storage drivers are supported:\n\n\n\n\n\n\n\n\nDriver\n\n\nDriver Name\n\n\n\n\n\n\n\n\n\n\nIsilon\n\n\nisilon\n\n\n\n\n\n\nScaleIO\n\n\nscaleio\n\n\n\n\n\n\nVirtualBox\n\n\nvirtualbox\n\n\n\n\n\n\n..more coming\n\n\n\n\n\n\n\n\n\n\nThe \nlibstorage.server.libstorage.storage.driver\n property can be used to\nactivate a storage drivers. That is not a typo; the \nlibstorage\n key is repeated\nbeneath \nlibstorage.server\n. This is because configuration property paths are\nabsolute, and when nested under an architectural component, such as\n\nlibstorage.server\n, the entire key path must be replicated.\n\n\nThat said, and this may seem to contradict the last point, the storage driver\nproperty is valid \nonly\n on the server. Well, not really. Internally the\n\nlibStorage\n client uses the same configuration property to denote its own\nstorage driver. This internal storage driver is actually how the \nlibStorage\n\nclient communicates with the \nlibStorage\n server.\n\n\nIntegration Drivers\n\n\nIntegration drivers enable \nlibStorage\n to integrate with schedulers and other\nstorage consumers, such as \nDocker\n or \nMesos\n. Currently the following\nintegration drivers are supported:\n\n\n\n\n\n\n\n\nDriver\n\n\nDriver Name\n\n\n\n\n\n\n\n\n\n\nDocker\n\n\ndocker\n\n\n\n\n\n\n\n\nThe integration driver \ndocker\n provides necessary functionality to enable\nmost consuming platforms to work with storage volumes.\n\n\nVolume Configuration\n\n\nThis section describes various global configuration options related to an\nintegration driver's volume operations, such as mounting and unmounting volumes.\n\n\nVolume Properties\n\n\nThe properties listed below are the global properties valid for an integration\ndriver's volume-related properties.\n\n\n\n\n\n\n\n\nparameter\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nlibstorage.integration.volume.operations.mount.preempt\n\n\nForcefully take control of volumes when requested\n\n\n\n\n\n\nlibstorage.integration.volume.operations.mount.path\n\n\nThe default host path for mounting volumes\n\n\n\n\n\n\nlibstorage.integration.volume.operations.mount.rootPath\n\n\nThe path within the volume to return to the integrator (ex. \n/data\n)\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.disable\n\n\nDisable the ability for a volume to be created\n\n\n\n\n\n\nlibstorage.integration.volume.operations.remove.disable\n\n\nDisable the ability for a volume to be removed\n\n\n\n\n\n\n\n\nThe properties in the next table are the configurable parameters that affect\nthe default values for volume creation requests.\n\n\n\n\n\n\n\n\nparameter\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.default.size\n\n\nSize in GB\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.default.iops\n\n\nIOPS\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.default.type\n\n\nType of Volume or Storage Pool\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.default.fsType\n\n\nType of filesystem for new volumes (ext4/xfs)\n\n\n\n\n\n\nlibstorage.integration.volume.operations.create.default.availabilityZone\n\n\nExtensible parameter per storage driver\n\n\n\n\n\n\n\n\nDisable Create\n\n\nThe disable create feature enables you to disallow any volume creation activity.\nAny requests will be returned in a successful manner, but the create will not\nget passed to the backend storage platform.\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        create:\n          disable: true\n\n\n\n\nDisable Remove\n\n\nThe disable remove feature enables you to disallow any volume removal activity.\nAny requests will be returned in a successful manner, but the remove will not\nget passed to the backend storage platform.\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        remove:\n          disable: true\n\n\n\n\nPreemption\n\n\nThere is a capability to preemptively detach any existing attachments to other\ninstances before attempting a mount.  This will enable use cases for\navailability where another instance must be able to take control of a volume\nwithout the current owner instance being involved.  The operation is considered\nequivalent to a power off of the existing instance for the device.\n\n\nExample configuration file follows:\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        mount:\n          preempt: true\n\n\n\n\n\n\n\n\n\n\nDriver\n\n\nSupported\n\n\n\n\n\n\n\n\n\n\nIsilon\n\n\nNot yet\n\n\n\n\n\n\nScaleIO\n\n\nYes\n\n\n\n\n\n\nVirtualBox\n\n\nYes\n\n\n\n\n\n\n\n\nIgnore Used Count\n\n\nBy default accounting takes place during operations that are performed\non \nMount\n, \nUnmount\n, and other operations.  This only has impact when running\nas a service through the HTTP/JSON interface since the counts are persisted\nin memory.  The purpose of respecting the \nUsed Count\n is to ensure that a\nvolume is not unmounted until the unmount requests have equaled the mount\nrequests.  \n\n\nIn the \nDocker\n use case if there are multiple containers sharing a volume\non the same host, the the volume will not be unmounted until the last container\nis stopped.  \n\n\nThe following setting should only be used if you wish to \ndisable\n this\nfunctionality.  This would make sense if the accounting is being done from\nhigher layers and all unmount operations should proceed without control.\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        unmount:\n          ignoreUsedCount: true\n\n\n\n\nCurrently a reset of the service will cause the counts to be reset.  This\nwill cause issues if \nmultiple containers\n are sharing a volume.  If you are\nsharing volumes, it is recommended that you reset the service along with the\naccompanying container runtime (if this setting is false) to ensure they are\nsynchronized.  \n\n\nVolume Path Cache\n\n\nIn order to optimize \nPath\n requests, the paths of actively mounted volumes\nreturned as the result of a \nList\n request are cached. Subsequent \nPath\n\nrequests for unmounted volumes will not dirty the cache. Only once a volume\nhas been mounted will the cache be marked dirty and the volume's path retrieved\nand cached once more.\n\n\nThe following configuration example illustrates the two path cache properties:\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        path:\n          cache:\n            enabled: true\n            async:   true\n\n\n\n\nVolume path caching is enabled and asynchronous by default, so it's possible to\nentirely omit the above configuration excerpt from a production deployment, and\nthe system will still use asynchronous caching. Setting the \nasync\n property to\n\nfalse\n simply means that the initial population of the cache will be handled\nsynchronously, slowing down the program's startup time.\n\n\nVolume Root Path\n\n\nWhen volumes are mounted there can be an additional path that is specified to\nbe created and passed as the valid mount point.  This is required for certain\napplications that do not want to place data from the root of a mount point.\n\n\nThe default is the \n/data\n path.  If a value is set by\n\nlinux.integration.volume.operations.mount.rootPath\n, then the default will be\noverwritten.\n\n\nlibstorage:\n  integration:\n    volume:\n      operations:\n        mount:\n          rootPath: /data", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/config/#configuring-libstorage", 
            "text": "Tweak this, turn that, peek behind the curtain...", 
            "title": "Configuring libStorage"
        }, 
        {
            "location": "/user-guide/config/#overview", 
            "text": "This page reviews how to configure  libStorage  to suit any environment,\nbeginning with the the most common use cases, exploring recommended guidelines,\nand finally, delving into the details of more advanced settings.", 
            "title": "Overview"
        }, 
        {
            "location": "/user-guide/config/#clientserver-configuration", 
            "text": "Except when specified otherwise, the configuration examples below assume the libStorage  client and server exist on the same host. However, that is not at\nall a requirement. It is fully possible, and in fact the entire purpose of libStorage , that the client and server be able to function on different\nsystems. One  libStorage  server should be able to support hundreds of clients.\nYet for the sake of completeness, the examples below show both configurations\nmerged.  When configuring a  libStorage  client and server for different systems, there\nwill be a few differences from the examples below:    The examples show  libStorage  configured with its server component hosted\n    on a UNIX socket. This is ideal for when the client/server exist on the same\n    host as it reduces security risks. However, in most real-world scenarios\n    the client and server are  not  residing on the same host, the\n     libStorage   server should use a TCP endpoint so it can be accessed\n    remotely.    In a distributed configuration the actual driver configuration sections\n    need only occur on the server-side. The entire purpose of  libStorage 's\n    distributed nature is to enable clients without any knowledge of how to\n    access a storage platform the ability to connect to a remote server that\n    maintains that storage platform access information.", 
            "title": "Client/Server Configuration"
        }, 
        {
            "location": "/user-guide/config/#basic-configuration", 
            "text": "This section outlines the most common configuration scenarios encountered by libStorage 's users.", 
            "title": "Basic Configuration"
        }, 
        {
            "location": "/user-guide/config/#simple", 
            "text": "The first example is a simple  libStorage  configuration with the VirtualBox\nstorage driver. The below example omits the host property, but the configuration\nis still valid. If the  libstorage.host  property is not found, the server is\nhosted via a temporary UNIX socket file in  /var/run/libstorage .   note  Please remember to replace the placeholders in the following examples\nwith values valid for the systems on which the examples are executed.  The example below specifies the  volumePath  property as $HOME/VirtualBox/Volumes . While the text  $HOME  will be replaced with\nthe actual value for that environment variable at runtime, the path may\nstill be invalid. The  volumePath  property should reflect a path on the\nsystem on which the VirtualBox server is running, and that is not always\nthe same system on which the  libStorage  server is running.  So please, make sure to update the  volumePath  property for the VirtualBox\ndriver to a path valid on the system on which the VirtualBox server is\nrunning.  The same goes for VirtualBox property  endpoint  as the VirtualBox\nweb service is not always available at  10.0.2.2:18083 .   libstorage:\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA", 
            "title": "Simple"
        }, 
        {
            "location": "/user-guide/config/#tcp", 
            "text": "The following example illustrates how to configure a  libStorage  client and\nserver running on the same host. The server has one endpoint on which it is\naccessible - a single TCP port, 7979, bound to the localhost network interface.  libstorage:\n  host: tcp://127.0.0.1:7979\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA", 
            "title": "TCP"
        }, 
        {
            "location": "/user-guide/config/#tcptls", 
            "text": "The following example illustrates how to configure a  libStorage  client and\nserver running on the same host. The server has one endpoint on which it is\naccessible - a single TCP port, 7979, bound to all of the host's network\ninterfaces. This means that the server is accessible via external clients, not\njust those running on the same host.  Because of the public nature of this  libStorage  server, it is a good idea to\nencrypt communications between client and server.  libstorage:\n  host: tcp://127.0.0.1:7979\n  client:\n    tls:\n      certFile: $HOME/.libstorage/libstorage-client.crt\n      keyFile: $HOME/.libstorage/libstorage-client.key\n      trustedCertsFile: $HOME/.libstorage/trusted-certs.crt\n  server:\n    tls:\n      certFile: /etc/libstorage/libstorage-server.crt\n      keyFile: /etc/libstorage/libstorage-server.key\n      trustedCertsFile: /etc/libstorage/trusted-certs.crt\n      clientCertRequired: true\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA  Please note that in the above example the property  libstorage.client  has been\nintroduced. This property is always present, even if not explicitly specified.\nIt exists to override  libStorage  properties for the client only, such as TLS\nsettings, logging, etc.", 
            "title": "TCP+TLS"
        }, 
        {
            "location": "/user-guide/config/#unix-socket", 
            "text": "For the security conscious, there is no safer way to run a client/server setup\non a single system than the option to use a UNIX socket. The socket offloads\nauthentication and relies on the file system file access to ensure authorized\nusers can use the  libStorage  API.  libstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA  It is possible to apply TLS to the UNIX socket. Refer to the TCP+TLS section\nfor applying TLS to the UNIX sockets.", 
            "title": "UNIX Socket"
        }, 
        {
            "location": "/user-guide/config/#multiple-endpoints", 
            "text": "There may be occasions when it is desirable to provide multiple ingress vectors\nfor the  libStorage  API. In these situations, configuring multiple endpoints\nis the solution. The below example illustrates how to configure three endpoints:     endpoint  protocol  address  tls  localhost only      sock  unix socket  /var/run/libstorage/localhost.sock  no  yes    private  tcp  127.0.0.1:7979  no  yes    public  tcp  *:7980  yes  no     libstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n    endpoints:\n      sock:\n        address: unix:///var/run/libstorage/localhost.sock\n      private:\n        address: tcp://127.0.0.1:7979\n      public:\n        address: tcp://:7980\n        tls:\n          certFile: /etc/libstorage/libstorage-server.crt\n          keyFile: /etc/libstorage/libstorage-server.key\n          trustedCertsFile: /etc/libstorage/trusted-certs.crt\n          clientCertRequired: true  With all three endpoints defined explicitly in the above example, why leave the\nproperty  libstorage.host  in the configuration at all? When there are no\nendpoints defined, the  libStorage  server will attempt to create a default\nendpoint using the value from the property  libstorage.host . However, even\nwhen there's at least one explicitly defined endpoint, the  libstorage.host \nproperty still serves a very important function -- it is the property used\nby the  libStorage  client to determine which to which endpoint to connect.", 
            "title": "Multiple Endpoints"
        }, 
        {
            "location": "/user-guide/config/#multiple-services", 
            "text": "All of the previous examples have used the VirtualBox storage driver as the\nsole measure of how to configure a  libStorage  service. However, it is possible\nto configure many services at the same time in order to provide access to\nmultiple storage drivers of different types, or even different configurations\nof the same driver.  The following example demonstrates how to configure three  libStorage  services:     service  driver      virtualbox-00  virtualbox    virtualbox-01  virtualbox    scaleio  scaleio     Notice how the  virtualbox-01  service includes an added  integration  section.\nThe integration definition refers to the integration interface and parameters\nspecific to incoming requests through this layer. In this case we defined libstorage.server.services.virtualbox-01  with the integration.volume.operations.create.default.size  parameter set. This enables all\ncreate requests that come in through  virtualbox-01  to have a default size of\n1GB. So although it is technically the same platform below the covers, virtualbox-00  requests may have different default values than those defined\nin  virtualbox-01 .  libstorage:\n  server:\n    services:\n      virtualbox-00:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes-00\n          controllerName: SATA\n      virtualbox-01:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes-01\n          controllerName: SATA\n        integration:\n          volume:\n            operations:\n              create:\n                default:\n                  size: 1 # GB\n      scaleio:\n        driver: scaleio\n        scaleio:\n          endpoint: https://gateway_ip/api\n          insecure: true\n          userName: username\n          password: password\n          systemName: tenantName\n          protectionDomainName: protectionDomainName\n          storagePoolName: storagePoolName  A very important point to make about the relationship between services and\nendpoints is that all configured services are available on all endpoints. In\nthe future this may change, and  libStorage  may support endpoint-specific\nservice definitions, but for now if a service is configured, it is accessible\nvia any of the available endpoint addresses.  Between the three services above, clearly one major difference is that two\nservices host one driver, VirtualBox, and the third service hosts ScaleIO.\nHowever, why two services for one driver, in this case, VirtualBox? Because,\nin addition to services being configured to host different types of drivers,\nservices can also host different driver configurations. In service virtualbox-00 , the volume path is  $HOME/VirtualBox/Volumes-00 ,\nwhereas for service  virtualbox-01 , the volume path is $HOME/VirtualBox/Volumes-01 .", 
            "title": "Multiple Services"
        }, 
        {
            "location": "/user-guide/config/#logging", 
            "text": "Sometimes it helps to see a little more, or maybe even a little less,\ninformation in the logs. Configuring logging is quite straight-forward:  libstorage:\n  logging:\n    level: warn\n  server:\n    logging:\n      level: info\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA  The  libStorage  configuration shown above uses a global log level of  warn ,\nand a more verbose,  info  log level for just the server.", 
            "title": "Logging"
        }, 
        {
            "location": "/user-guide/config/#advanced-configuration", 
            "text": "The following sections detail every last aspect of how  libStorage  works and can\nbe configured.", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/user-guide/config/#embedded-configuration", 
            "text": "If  libStorage  is embedded into another application, such as REX-Ray , then that application may\nmanage its own configuration and supply the embedded  libStorage  instance\ndirectly with a configuration object. In this scenario, the  libStorage \nconfiguration files are ignored in deference to the embedding application.", 
            "title": "Embedded Configuration"
        }, 
        {
            "location": "/user-guide/config/#data-directories", 
            "text": "The first time  libStorage  is executed it will create several directories if\nthey do not already exist:   /etc/libstorage  /var/log/libstorage  /var/run/libstorage  /var/lib/libstorage   The above directories will contain configuration files, logs, PID files, and\nmounted volumes. However, the location of these directories can also be\ninfluenced with the environment variable  LIBSTORAGE_HOME . All of the above\ndata directories will be placed in their same paths, but prefixed by the path\nspecified via  LIBSTORAGE_HOME , if  LIBSTORAGE_HOME  is in fact specified.", 
            "title": "Data Directories"
        }, 
        {
            "location": "/user-guide/config/#configuration-methods", 
            "text": "There are three ways to configure  libStorage :   Command line options  Environment variables  Configuration files   The order of the items above is also the order of precedence when considering\noptions set in multiple locations that may override one another. Values set\nvia CLI flags have the highest order of precedence, followed by values set by\nenvironment variables, followed, finally, by values set in configuration files.", 
            "title": "Configuration Methods"
        }, 
        {
            "location": "/user-guide/config/#configuration-files", 
            "text": "There are two  libStorage  configuration files - global and user:   /etc/libstorage/config.yml  $HOME/.libstorage/config.yml   Please note that while the user configuration file is located inside the user's\nhome directory, this is the directory of the user that starts  libStorage . And\nif  libStorage  is being started as a service, then  sudo  is likely being used,\nwhich means that  $HOME/.libstorage/config.yml  won't point to  your  home\ndirectory, but rather  /root/.libstorage/config.yml .", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/user-guide/config/#configuration-properties", 
            "text": "The section  Configuration Methods  mentions there are\nthree ways to configure libStorage: config files, environment variables, and the\ncommand line. However, this section will illuminate the relationship between the\nnames of the configuration file properties, environment variables, and CLI\nflags.  Below is a simple configuration file that tells the  libStorage  client where\nthe  libStorage  server is hosted:  libstorage:\n  host: tcp://192.168.0.20:7979  The property  libstorage.host  is a string. This value can also be set via\nenvironment variables or the command line, but to do so requires knowing the\nnames of the environment variables or CLI flags to use. Luckily those are very\neasy to figure out just by knowing the property names.  All properties that might appear in the  libStorage  configuration file\nfall under some type of heading. For example, take the default configuration\nabove.  The rule for environment variables is as follows:   Each nested level becomes a part of the environment variable name followed\n    by an underscore  _  except for the terminating part.  The entire environment variable name is uppercase.   Nested properties follow these rules for CLI flags:   The root level's first character is lower-cased with the rest of the root\n    level's text left unaltered.  The remaining levels' first characters are all upper-cased with the the\n    remaining text of that level left unaltered.  All levels are then concatenated together.   The following example builds on the previous. In this case we have added logging\ndirectives to the client instance and reference how their transformation in\nthe table below the example.    libstorage:\n    host: tcp://192.168.0.20:7979\n    logging:\n      level: warn\n      stdout:\n      stderr:\n      httpRequests: false\n      httpResponses: false  The following table illustrates the transformations:     Property Name  Environment Variable  CLI Flag      libstorage.host  LIBSTORAGE_HOST  --libstorageHost    libstorage.logging.level  LIBSTORAGE_LOGGING_LEVEL  --libstorageLoggingLevel    libstorage.logging.stdout  LIBSTORAGE_LOGGING_STDOUT  --libstorageLoggingStdout    libstorage.logging.stderr  LIBSTORAGE_LOGGING_STDERR  --libstorageLoggingStderr    libstorage.logging.httpRequests  LIBSTORAGE_LOGGING_HTTPREQUESTS  --libstorageLoggingHttpRequests    libstorage.logging.httpResponses  LIBSTORAGE_LOGGING_HTTPRESPONSES  --libstorageLoggingHttpResponses", 
            "title": "Configuration Properties"
        }, 
        {
            "location": "/user-guide/config/#inherited-properties", 
            "text": "Referring to the section on defining Multiple Services , there is also another way\nto define the TLS settings for the external TCP endpoint. The same configuration\ncan be rewritten and simplified in the process:  libstorage:\n  integration:\n    volume:\n      operations:\n        create:\n          default:\n            size: 1 # GB\n  server:\n    virtualbox:\n      endpoint:       http://10.0.2.2:18083\n      tls:            false\n      controllerName: SATA\n    services:\n      virtualbox-00:\n        driver: virtualbox\n        virtualbox:\n          volumePath: $HOME/VirtualBox/Volumes-00\n      virtualbox-01:\n        driver: virtualbox\n        virtualbox:\n          volumePath: $HOME/VirtualBox/Volumes-01  The above example may look different than the previous one, but it's actually\nthe same with a minor tweak in order to simplify configuration.  While there are still two VirtualBox services defined,  virtualbox-00  and virtualbox-01 , neither service contains configuration information about the\nVirtualBox driver other than the  volumePath  property. This is because the\nchange affected above is to take advantage of inherited properties.  When a property is omitted,  libStorage  traverses the configuration instance\nupwards, checking certain, predefined levels known as \"scopes\" to see if the\nproperty value exists there. All configured services represent a valid\nconfiguration scope as does  libstorage.server .  Thus when the VirtualBox driver is initialized and it checks for its properties,\nwhile the driver may only find the  volumePath  property defined under the\nconfigured service scope, the property access attempt travels up the\nconfiguration stack until it hits the  libstorage.server  scope where the\nremainder of the VirtualBox driver's properties  are  defined.", 
            "title": "Inherited Properties"
        }, 
        {
            "location": "/user-guide/config/#overriding-inherited-properties", 
            "text": "It's also possible to override inherited properties as is demonstrated in the Logging configuration example  above:  libstorage:\n  logging:\n    level: warn\n  integration:\n    volume:\n      operations:\n        create:\n          default:\n            size: 1 # GB\n  server:\n    logging:\n      level: info\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA  Note that while the log level is defined at the root of the config, it's also\ndefined at  libstorage.server.logging.level . The latter value of  info \noverrides the former value of  warn . Also please remember that even had the\nlatter, server-specific value of  info  not been defined, an attempt by to\naccess the log level by the server would be perfectly valid since the attempt\nwould traverse up the configuration data until it found the log level defined\nat the root of the configuration.", 
            "title": "Overriding Inherited Properties"
        }, 
        {
            "location": "/user-guide/config/#logging-configuration", 
            "text": "The  libStorage  log level determines the level of verbosity emitted by the\ninternal logger. The default level is  warn , but there are three other levels\nas well:     Log Level  Description      error  Log only errors    warn  Log errors and anything out of place    info  Log errors, warnings, and workflow messages    debug  Log everything", 
            "title": "Logging Configuration"
        }, 
        {
            "location": "/user-guide/config/#tasks-configuration", 
            "text": "All operations received by the libStorage API are immediately enqueued into a\nTask Service in order to divorce the business objective from the scope of the\nHTTP request that delivered it. If a task completes before the HTTP request\ntimes out, the result of the task is written to the HTTP response and sent to\nthe client. However, if the operation is long-lived and continues to execute\nafter the original HTTP request has timed out, the goroutine running the\noperation will finish regardless.  In the case of such a timeout event, the client receives an HTTP status 408 -\nRequest Timeout. The HTTP response body also includes the task ID which can\nbe used to monitor the state of the remote call. The following resource URI can\nbe used to retrieve information about a task:  GET /tasks/${taskID}  For systems that experience heavy loads the task system can also be a source of\npotential resource issues. Because tasks are kept indefinitely at this point in\ntime, too many tasks over a long period of time can result in a massive memory\nconsumption, with reports of up to 50GB and more.  That's why the configuration property  libstorage.server.tasks.logTimeout  is\navailable to adjust how long a task is logged before it is removed from memory.\nThe default value is  0  -- that is, do not log the task in memory at all.  While this is in contradiction to the task retrieval example above --\nobviously a task cannot be retrieved if it is not retained -- testing and\nbenchmarks have shown it is too dangerous to enable task retention by default.\nInstead tasks are removed immediately upon completion.  The follow configuration example illustrates a libStorage server that keeps\ntasks logged for 10 minutes before purging them from memory:  libstorage:\n  server:\n    tasks:\n      logTimeout: 10m  The  libstorage.server.tasks.logTimeout  property can be set to any value that\nis parseable by the Golang time.ParseDuration  function. For\nexample,  1000ms ,  10s ,  5m , and  1h  are all valid values.", 
            "title": "Tasks Configuration"
        }, 
        {
            "location": "/user-guide/config/#driver-configuration", 
            "text": "There are three types of drivers:   OS Drivers  Storage Drivers  Integration Drivers", 
            "title": "Driver Configuration"
        }, 
        {
            "location": "/user-guide/config/#os-drivers", 
            "text": "Operating system (OS) drivers enable  libStorage  to manage storage on\nthe underlying OS. Currently the following OS drivers are supported:     Driver  Driver Name      Linux  linux     The OS driver  linux  is automatically activated when  libStorage  is running on\nthe Linux OS.", 
            "title": "OS Drivers"
        }, 
        {
            "location": "/user-guide/config/#storage-drivers", 
            "text": "Storage drivers enable  libStorage  to communicate with direct-attached or\nremote storage systems. Currently the following storage drivers are supported:     Driver  Driver Name      Isilon  isilon    ScaleIO  scaleio    VirtualBox  virtualbox    ..more coming      The  libstorage.server.libstorage.storage.driver  property can be used to\nactivate a storage drivers. That is not a typo; the  libstorage  key is repeated\nbeneath  libstorage.server . This is because configuration property paths are\nabsolute, and when nested under an architectural component, such as libstorage.server , the entire key path must be replicated.  That said, and this may seem to contradict the last point, the storage driver\nproperty is valid  only  on the server. Well, not really. Internally the libStorage  client uses the same configuration property to denote its own\nstorage driver. This internal storage driver is actually how the  libStorage \nclient communicates with the  libStorage  server.", 
            "title": "Storage Drivers"
        }, 
        {
            "location": "/user-guide/config/#integration-drivers", 
            "text": "Integration drivers enable  libStorage  to integrate with schedulers and other\nstorage consumers, such as  Docker  or  Mesos . Currently the following\nintegration drivers are supported:     Driver  Driver Name      Docker  docker     The integration driver  docker  provides necessary functionality to enable\nmost consuming platforms to work with storage volumes.", 
            "title": "Integration Drivers"
        }, 
        {
            "location": "/user-guide/config/#volume-configuration", 
            "text": "This section describes various global configuration options related to an\nintegration driver's volume operations, such as mounting and unmounting volumes.", 
            "title": "Volume Configuration"
        }, 
        {
            "location": "/user-guide/config/#volume-properties", 
            "text": "The properties listed below are the global properties valid for an integration\ndriver's volume-related properties.     parameter  description      libstorage.integration.volume.operations.mount.preempt  Forcefully take control of volumes when requested    libstorage.integration.volume.operations.mount.path  The default host path for mounting volumes    libstorage.integration.volume.operations.mount.rootPath  The path within the volume to return to the integrator (ex.  /data )    libstorage.integration.volume.operations.create.disable  Disable the ability for a volume to be created    libstorage.integration.volume.operations.remove.disable  Disable the ability for a volume to be removed     The properties in the next table are the configurable parameters that affect\nthe default values for volume creation requests.     parameter  description      libstorage.integration.volume.operations.create.default.size  Size in GB    libstorage.integration.volume.operations.create.default.iops  IOPS    libstorage.integration.volume.operations.create.default.type  Type of Volume or Storage Pool    libstorage.integration.volume.operations.create.default.fsType  Type of filesystem for new volumes (ext4/xfs)    libstorage.integration.volume.operations.create.default.availabilityZone  Extensible parameter per storage driver", 
            "title": "Volume Properties"
        }, 
        {
            "location": "/user-guide/config/#disable-create", 
            "text": "The disable create feature enables you to disallow any volume creation activity.\nAny requests will be returned in a successful manner, but the create will not\nget passed to the backend storage platform.  libstorage:\n  integration:\n    volume:\n      operations:\n        create:\n          disable: true", 
            "title": "Disable Create"
        }, 
        {
            "location": "/user-guide/config/#disable-remove", 
            "text": "The disable remove feature enables you to disallow any volume removal activity.\nAny requests will be returned in a successful manner, but the remove will not\nget passed to the backend storage platform.  libstorage:\n  integration:\n    volume:\n      operations:\n        remove:\n          disable: true", 
            "title": "Disable Remove"
        }, 
        {
            "location": "/user-guide/config/#preemption", 
            "text": "There is a capability to preemptively detach any existing attachments to other\ninstances before attempting a mount.  This will enable use cases for\navailability where another instance must be able to take control of a volume\nwithout the current owner instance being involved.  The operation is considered\nequivalent to a power off of the existing instance for the device.  Example configuration file follows:  libstorage:\n  integration:\n    volume:\n      operations:\n        mount:\n          preempt: true     Driver  Supported      Isilon  Not yet    ScaleIO  Yes    VirtualBox  Yes", 
            "title": "Preemption"
        }, 
        {
            "location": "/user-guide/config/#ignore-used-count", 
            "text": "By default accounting takes place during operations that are performed\non  Mount ,  Unmount , and other operations.  This only has impact when running\nas a service through the HTTP/JSON interface since the counts are persisted\nin memory.  The purpose of respecting the  Used Count  is to ensure that a\nvolume is not unmounted until the unmount requests have equaled the mount\nrequests.    In the  Docker  use case if there are multiple containers sharing a volume\non the same host, the the volume will not be unmounted until the last container\nis stopped.    The following setting should only be used if you wish to  disable  this\nfunctionality.  This would make sense if the accounting is being done from\nhigher layers and all unmount operations should proceed without control.  libstorage:\n  integration:\n    volume:\n      operations:\n        unmount:\n          ignoreUsedCount: true  Currently a reset of the service will cause the counts to be reset.  This\nwill cause issues if  multiple containers  are sharing a volume.  If you are\nsharing volumes, it is recommended that you reset the service along with the\naccompanying container runtime (if this setting is false) to ensure they are\nsynchronized.", 
            "title": "Ignore Used Count"
        }, 
        {
            "location": "/user-guide/config/#volume-path-cache", 
            "text": "In order to optimize  Path  requests, the paths of actively mounted volumes\nreturned as the result of a  List  request are cached. Subsequent  Path \nrequests for unmounted volumes will not dirty the cache. Only once a volume\nhas been mounted will the cache be marked dirty and the volume's path retrieved\nand cached once more.  The following configuration example illustrates the two path cache properties:  libstorage:\n  integration:\n    volume:\n      operations:\n        path:\n          cache:\n            enabled: true\n            async:   true  Volume path caching is enabled and asynchronous by default, so it's possible to\nentirely omit the above configuration excerpt from a production deployment, and\nthe system will still use asynchronous caching. Setting the  async  property to false  simply means that the initial population of the cache will be handled\nsynchronously, slowing down the program's startup time.", 
            "title": "Volume Path Cache"
        }, 
        {
            "location": "/user-guide/config/#volume-root-path", 
            "text": "When volumes are mounted there can be an additional path that is specified to\nbe created and passed as the valid mount point.  This is required for certain\napplications that do not want to place data from the root of a mount point.  The default is the  /data  path.  If a value is set by linux.integration.volume.operations.mount.rootPath , then the default will be\noverwritten.  libstorage:\n  integration:\n    volume:\n      operations:\n        mount:\n          rootPath: /data", 
            "title": "Volume Root Path"
        }, 
        {
            "location": "/user-guide/storage-providers/", 
            "text": "Storage Providers\n\n\nConnecting storage and platforms...\n\n\n\n\nOverview\n\n\nThis page reviews the storage providers and platforms supported by \nlibStorage\n.\n\n\nClient/Server Configuration\n\n\nRegarding the examples below, please\n\nread the provision\n about\nclient/server configurations before proceeding.\n\n\nIsilon\n\n\nThe Isilon driver registers a storage driver named \nisilon\n with the\n\nlibStorage\n driver manager and is used to connect and manage Isilon NAS\nstorage. The driver creates logical volumes in directories on the Isilon\ncluster. Volumes are exported via NFS and restricted to a single client at a\ntime. Quotas can also be used to ensure that a volume directory doesn't exceed\na specified size.\n\n\nConfiguration\n\n\nThe following is an example configuration of the Isilon driver.\n\n\nisilon:\n  endpoint: https://endpoint:8080\n  insecure: true\n  username: username\n  group: groupname\n  password: password\n  volumePath: /libstorage\n  nfsHost: nfsHost\n  dataSubnet: subnet\n  quotas: true\n\n\n\n\nFor information on the equivalent environment variable and CLI flag names\nplease see the section on how configuration properties are\n\ntransformed\n.\n\n\nExtra Parameters\n\n\nThe following items are configurable specific to this driver.\n\n\n\n\nvolumePath\n represents the location under \n/ifs/volumes\n to allow volumes to\n   be created and removed.\n\n\nnfsHost\n is the configurable host used when mounting exports\n\n\ndataSubnet\n is the subnet the REX-Ray driver is running on\n\n\n\n\nOptional Parameters\n\n\nThe following items are not required, but available to this driver.\n\n\n\n\ninsecure\n defaults to \nfalse\n.\n\n\ngroup\n defaults to the group of the user specified in the configuration.\n   Only use this option if you need volumes to be created with a different\n   group.\n\n\nvolumePath\n defaults to \"\". This will have all new volumes created directly\n   under \n/ifs/volumes\n.\n\n\nquotas\n defaults to \nfalse\n. Set to \ntrue\n if you have a SmartQuotas\n   license enabled.\n\n\n\n\nActivating the Driver\n\n\nTo activate the Isilon driver please follow the instructions for\n\nactivating storage drivers\n,\nusing \nisilon\n as the driver name.\n\n\nExamples\n\n\nBelow is a full \nconfig.yml\n file that works with Isilon.\n\n\nlibstorage:\n  server:\n    services:\n      isilon:\n        driver: isilon\n        isilon:\n          endpoint: https://endpoint:8080\n          insecure: true\n          username: username\n          password: password\n          volumePath: /libstorage\n          nfsHost: nfsHost\n          dataSubnet: subnet\n          quotas: true\n\n\n\n\nInstructions\n\n\nIt is expected that the \nvolumePath\n exists already within the Isilon system.\nThis example would reflect a directory create under \n/ifs/volumes/libstorage\n\nfor created volumes. It is not necessary to export this volume. The \ndataSubnet\n\nparameter is required so the Isilon driver can restrict access to attached\nvolumes to the host that REX-Ray is running on.\n\n\nIf \nquotas\n are enabled, a SmartQuotas license must also be enabled on the\nIsilon cluster for the capacity size functionality of \nlibStorage\n to work.\n\n\nA SnapshotIQ license must be enabled on the Isilon cluster for the snapshot\nfunctionality of \nlibStorage\n to work.\n\n\nCaveats\n\n\nThe Isilon driver is not without its caveats:\n\n\n\n\nThe account used to access the Isilon cluster must be in a role with the\n  following privileges:\n\n\nNamespace Access (ISI_PRIV_NS_IFS_ACCESS)\n\n\nPlatform API (ISI_PRIV_LOGIN_PAPI)\n\n\nNFS (ISI_PRIV_NFS)\n\n\nRestore (ISI_PRIV_IFS_RESTORE)\n\n\nQuota (ISI_PRIV_QUOTA)          (if \nquotas\n are enabled)\n\n\nSnapshot (ISI_PRIV_SNAPSHOT)    (if snapshots are used)\n\n\n\n\n\n\n\n\nScaleIO\n\n\nThe ScaleIO driver registers a storage driver named \nscaleio\n with the\n\nlibStorage\n driver manager and is used to connect and manage ScaleIO storage.\n\n\nRequirements\n\n\n\n\nThe ScaleIO \nREST Gateway\n is required for the driver to function.\n\n\nThe \nlibStorage\n client or application that embeds the \nlibStorage\n client\n   must reside on a host that has the SDC client installed. The command\n   \n/opt/emc/scaleio/sdc/bin/drv_cfg --query_guid\n should be executable and\n   should return the local SDC GUID.\n\n\nThe \nofficial\n\n   Oracle Java Runtime Environment (JRE) is required. During testing, use of the\n   Open Java Development Kit (JDK) resulted in unexpected errors.\n\n\n\n\nConfiguration\n\n\nThe following is an example with all possible fields configured.  For a running\nexample see the \nExamples\n section.\n\n\nscaleio:\n  endpoint:             https://host_ip/api\n  apiVersion:           \n2.0\n\n  insecure:             false\n  useCerts:             true\n  userName:             admin\n  password:             mypassword\n  systemID:             0\n  systemName:           sysv\n  protectionDomainID:   0\n  protectionDomainName: corp\n  storagePoolID:        0\n  storagePoolName:      gold\n  thinOrThick:          ThinProvisioned\n\n\n\n\nConfiguration Notes\n\n\n\n\nThe \napiVersion\n can optionally be set here to force certain API behavior.\nThe default is to retrieve the endpoint API, and pass this version during calls.\n\n\ninsecure\n should be set to \ntrue\n if you have not loaded the SSL\ncertificates on the host.  A successful wget or curl should be possible without\nSSL errors to the API \nendpoint\n in this case.\n\n\nuseCerts\n should only be set if you want to leverage the internal SSL\ncertificates.  This would be useful if you are deploying the REX-Ray binary\non a host that does not have any certificates installed.\n\n\nsystemID\n takes priority over \nsystemName\n.\n\n\nprotectionDomainID\n takes priority over \nprotectionDomainName\n.\n\n\nstoragePoolID\n takes priority over \nstoragePoolName\n.\n\n\nthinkOrThick\n determines whether to provision as the default\n\nThinProvisioned\n, or \nThickProvisioned\n.\n\n\n\n\nFor information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are\n\ntransformed\n.\n\n\nRuntime Behavior\n\n\nThe \nstorageType\n field that is configured per volume is considered the\nScaleIO Storage Pool.  This can be configured by default with the \nstoragePool\n\nsetting.  It is important that you create unique names for your Storage Pools\non the same ScaleIO platform.  Otherwise, when specifying \nstorageType\n it\nmay choose at random which \nprotectionDomain\n the pool comes from.\n\n\nThe \navailabilityZone\n field represents the ScaleIO Protection Domain.\n\n\nConfiguring the Gateway\n\n\n\n\nInstall the \nEMC-ScaleIO-gateway\n package.\n\n\nEdit the\n\n/opt/emc/scaleio/gateway/webapps/ROOT/WEB-INF/classes/gatewayUser.properties\n\nfile and append the proper MDM IP addresses to the following \nmdm.ip.addresses=\n\nparameter.\n\n\nBy default the password is the same as your administrative MDM password.\n\n\nStart the gateway \nservice scaleio-gateway start\n.\n\n\nWith 1.32 we have noticed a restart of the gateway may be necessary as well\nafter an initial install with \nservice scaleio-gateway restart\n.\n\n\n\n\nActivating the Driver\n\n\nTo activate the ScaleIO driver please follow the instructions for\n\nactivating storage drivers\n,\nusing \nscaleio\n as the driver name.\n\n\nTroubleshooting\n\n\n\n\nVerify your parameters for \nsystem\n, \nprotectionDomain\n, and\n\nstoragePool\n are correct.\n\n\nVerify that have the ScaleIO SDC service installed with\n\nrpm -qa EMC-ScaleIO-sdc\n\n\nVerify that the following command returns the local SDC GUID\n\n/opt/emc/scaleio/sdc/bin/drv_cfg --query_guid\n.\n\n\nEnsure that you are able to open a TCP connection to the gateway with the\naddress that you will be supplying below in the \ngateway_ip\n parameter.  For\nexample \ntelnet gateway_ip 443\n should open a successful connection.  Removing\nthe \nEMC-ScaleIO-gateway\n package and reinstalling can force re-creation of\nself-signed certs which may help resolve gateway problems.  Also try restarting\nthe gateway with \nservice scaleio-gateway restart\n.\n\n\nEnsure that you have the correct authentication credentials for the gateway.\nThis can be done with a curl login. You should receive an authentication\ntoken in return.\n\ncurl --insecure --user admin:XScaleio123 https://gw_ip:443/api/login\n\n\nPlease review the gateway log at\n\n/opt/emc/scaleio/gateway/logs/catalina.out\n for errors.\n\n\n\n\nExamples\n\n\nBelow is a full \nconfig.yml\n file that works with ScaleIO.\n\n\nlibstorage:\n  server:\n    services:\n      scaleio:\n        driver: scaleio\n        scaleio:\n          endpoint: https://gateway_ip/api\n          insecure: true\n          userName: username\n          password: password\n          systemName: tenantName\n          protectionDomainName: protectionDomainName\n          storagePoolName: storagePoolName\n\n\n\n\nVirtualBox\n\n\nThe VirtualBox driver registers a storage driver named \nvirtualbox\n with the\n\nlibStorage\n driver manager and is used by VirtualBox's VMs to connect and\nmanage volumes provided by VirtualBox.\n\n\nPrerequisites\n\n\nIn order to leverage the \nvirtualbox\n driver, the \nlibStorage\n client or must\nbe located on each VM that you wish to be able to consume external volumes.\nThe driver leverages the \nvboxwebserv\n HTTP SOAP API which is a process that\nmust be started from the VirtualBox \nhost\n (ie OS X) using\n\nvboxwebsrv -H 0.0.0.0 -v\n or additionally with \n-b\n for running in the\nbackground. This allows the VMs running \nlibStorage\n to remotely make calls to\nthe underlying VirtualBox application. A test for connectivity can be done with\n\ntelnet virtualboxip 18083\n from the VM. The \nvirtualboxip\n is what you\nwould put in the \nendpoint\n value.\n\n\nLeveraging authentication for the VirtualBox webserver is optiona.. The HTTP\nSOAP API can have authentication disabled by running\n\nVBoxManage setproperty websrvauthlibrary null\n.\n\n\nHot-Plugging is required, which limits the usefulness of this driver to \nSATA\n\nonly.  Ensure that your VM has \npre-created\n this controller and it is\nnamed \nSATA\n.  Otherwise the \ncontrollerName\n field must be populated\nwith the name of the controller you wish to use.  The port count must be set\nmanually as it cannot be increased when the VMs are on.  A count of \n30\n\nis suggested.\n\n\nVirtualBox 5.0.10+ must be used.\n\n\nConfiguration\n\n\nThe following is an example configuration of the VirtualBox driver.\n\nThe \nlocalMachineNameOrId\n parameter is for development use where you force\n\nlibStorage\n to use a specific VM identity.  Choose a \nvolumePath\n to store the\nvolume files or virtual disks.  This path should be created ahead of time.\n\n\nvirtualbox:\n  endpoint: http://virtualboxhost:18083\n  userName: optional\n  password: optional\n  tls: false\n  volumePath: $HOME/VirtualBox/Volumes\n  controllerName: name\n  localMachineNameOrId: forDevelopmentUse\n\n\n\n\nFor information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are\n\ntransformed\n.\n\n\nActivating the Driver\n\n\nTo activate the VirtualBox driver please follow the instructions for\n\nactivating storage drivers\n,\nusing \nvirtualbox\n as the driver name.\n\n\nExamples\n\n\nBelow is a working \nconfig.yml\n file that works with VirtualBox.\n\n\nlibstorage:\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nCaveats\n\n\n\n\nSnapshot and create volume from volume functionality is not available yet\n  with this driver.\n\n\nThe driver supports VirtualBox 5.0.10+\n\n\n\n\nAWS EFS\n\n\nThe AWS EFS driver registers a storage driver named \nefs\n with the\n\nlibStorage\n driver manager and is used to connect and manage AWS Elastic File\nSystems.\n\n\nRequirements\n\n\n\n\nAWS account\n\n\nVPC - EFS can be accessed within VPC\n\n\nAWS Credentials\n\n\n\n\nConfiguration\n\n\nThe following is an example with all possible fields configured.  For a running\nexample see the \nExamples\n section.\n\n\nefs:\n  accessKey:      XXXXXXXXXX\n  secretKey:      XXXXXXXXXX\n  securityGroups: sg-XXXXXXX,sg-XXXXXX0,sg-XXXXXX1\n  region:         us-east-1\n  tag:            test\n\n\n\n\nConfiguration Notes\n\n\n\n\nThe \naccessKey\n and \nsecretKey\n configuration parameters are optional and should\nbe used when explicit AWS credentials configuration needs to be provided. EFS driver\nuses official golang AWS SDK library and supports all other ways of providing\naccess credentials, like environment variables or instance profile IAM permissions.\n\n\nregion\n represents AWS region where should be EFS provisioned. See official AWS\ndocumentation for list of supported regions.\n\n\nsecurityGroups\n list of security groups attached to \nMountPoint\n instances.\nIf no security groups are provided the default VPC security group is used.\n\n\ntag\n is used to partition multiple services within single AWS account and is\nused as prefix for EFS names in format \n[tagprefix]/volumeName\n.\n\n\n\n\nFor information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are\n\ntransformed\n.\n\n\nRuntime Behavior\n\n\nAWS EFS storage driver creates one EFS FileSystem per volume and provides root\nof the filesystem as NFS mount point. Volumes aren't attached to instances\ndirectly but rather exposed to each subnet by creating \nMountPoint\n in each VPC\nsubnet. When detaching volume from instance no action is taken as there isn't\ngood way to figure out if there are other instances in same subnet using\n\nMountPoint\n that is being detached. There is no charge for \nMountPoint\n\nso they are removed only once whole volume is deleted.\n\n\nBy default all EFS instances are provisioned as \ngeneralPurpose\n performance mode.\n\nmaxIO\n EFS type can be provisioned by providing \nmaxIO\n flag as \nvolumetype\n.\n\n\nIts possible to mount same volume to multiple container on a single EC2 instance\nas well as use single volume across multiple EC2 instances at the same time.\n\n\nNOTE\n: Each EFS FileSystem can be accessed only from single VPC at the time.\n\n\nActivating the Driver\n\n\nTo activate the AWS EFS driver please follow the instructions for\n\nactivating storage drivers\n,\nusing \nefs\n as the driver name.\n\n\nTroubleshooting\n\n\n\n\nMake sure that AWS credentials (user or role) has following AWS permissions on\n  \nlibStorage\n server instance that will be making calls to AWS API:\n\n\nelasticfilesystem:CreateFileSystem\n\n\nelasticfilesystem:CreateMountTarget\n\n\nec2:DescribeSubnets\n\n\nec2:DescribeNetworkInterfaces\n\n\nec2:CreateNetworkInterface\n\n\nelasticfilesystem:CreateTags\n\n\nelasticfilesystem:DeleteFileSystem\n\n\nelasticfilesystem:DeleteMountTarget\n\n\nec2:DeleteNetworkInterface\n\n\nelasticfilesystem:DescribeFileSystems\n\n\nelasticfilesystem:DescribeMountTargets\n\n\n\n\nExamples\n\n\nBelow is a working \nconfig.yml\n file that works with AWS EFS.\n\n\nlibstorage:\n  server:\n    services:\n      efs:\n        driver: efs\n        efs:\n          accessKey:      XXXXXXXXXX\n          secretKey:      XXXXXXXXXX\n          securityGroups: sg-XXXXXXX,sg-XXXXXX0,sg-XXXXXX1\n          region:         us-east-1\n          tag:            test", 
            "title": "Storage Providers"
        }, 
        {
            "location": "/user-guide/storage-providers/#storage-providers", 
            "text": "Connecting storage and platforms...", 
            "title": "Storage Providers"
        }, 
        {
            "location": "/user-guide/storage-providers/#overview", 
            "text": "This page reviews the storage providers and platforms supported by  libStorage .", 
            "title": "Overview"
        }, 
        {
            "location": "/user-guide/storage-providers/#clientserver-configuration", 
            "text": "Regarding the examples below, please read the provision  about\nclient/server configurations before proceeding.", 
            "title": "Client/Server Configuration"
        }, 
        {
            "location": "/user-guide/storage-providers/#isilon", 
            "text": "The Isilon driver registers a storage driver named  isilon  with the libStorage  driver manager and is used to connect and manage Isilon NAS\nstorage. The driver creates logical volumes in directories on the Isilon\ncluster. Volumes are exported via NFS and restricted to a single client at a\ntime. Quotas can also be used to ensure that a volume directory doesn't exceed\na specified size.", 
            "title": "Isilon"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration", 
            "text": "The following is an example configuration of the Isilon driver.  isilon:\n  endpoint: https://endpoint:8080\n  insecure: true\n  username: username\n  group: groupname\n  password: password\n  volumePath: /libstorage\n  nfsHost: nfsHost\n  dataSubnet: subnet\n  quotas: true  For information on the equivalent environment variable and CLI flag names\nplease see the section on how configuration properties are transformed .", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/storage-providers/#extra-parameters", 
            "text": "The following items are configurable specific to this driver.   volumePath  represents the location under  /ifs/volumes  to allow volumes to\n   be created and removed.  nfsHost  is the configurable host used when mounting exports  dataSubnet  is the subnet the REX-Ray driver is running on", 
            "title": "Extra Parameters"
        }, 
        {
            "location": "/user-guide/storage-providers/#optional-parameters", 
            "text": "The following items are not required, but available to this driver.   insecure  defaults to  false .  group  defaults to the group of the user specified in the configuration.\n   Only use this option if you need volumes to be created with a different\n   group.  volumePath  defaults to \"\". This will have all new volumes created directly\n   under  /ifs/volumes .  quotas  defaults to  false . Set to  true  if you have a SmartQuotas\n   license enabled.", 
            "title": "Optional Parameters"
        }, 
        {
            "location": "/user-guide/storage-providers/#activating-the-driver", 
            "text": "To activate the Isilon driver please follow the instructions for activating storage drivers ,\nusing  isilon  as the driver name.", 
            "title": "Activating the Driver"
        }, 
        {
            "location": "/user-guide/storage-providers/#examples", 
            "text": "Below is a full  config.yml  file that works with Isilon.  libstorage:\n  server:\n    services:\n      isilon:\n        driver: isilon\n        isilon:\n          endpoint: https://endpoint:8080\n          insecure: true\n          username: username\n          password: password\n          volumePath: /libstorage\n          nfsHost: nfsHost\n          dataSubnet: subnet\n          quotas: true", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/storage-providers/#instructions", 
            "text": "It is expected that the  volumePath  exists already within the Isilon system.\nThis example would reflect a directory create under  /ifs/volumes/libstorage \nfor created volumes. It is not necessary to export this volume. The  dataSubnet \nparameter is required so the Isilon driver can restrict access to attached\nvolumes to the host that REX-Ray is running on.  If  quotas  are enabled, a SmartQuotas license must also be enabled on the\nIsilon cluster for the capacity size functionality of  libStorage  to work.  A SnapshotIQ license must be enabled on the Isilon cluster for the snapshot\nfunctionality of  libStorage  to work.", 
            "title": "Instructions"
        }, 
        {
            "location": "/user-guide/storage-providers/#caveats", 
            "text": "The Isilon driver is not without its caveats:   The account used to access the Isilon cluster must be in a role with the\n  following privileges:  Namespace Access (ISI_PRIV_NS_IFS_ACCESS)  Platform API (ISI_PRIV_LOGIN_PAPI)  NFS (ISI_PRIV_NFS)  Restore (ISI_PRIV_IFS_RESTORE)  Quota (ISI_PRIV_QUOTA)          (if  quotas  are enabled)  Snapshot (ISI_PRIV_SNAPSHOT)    (if snapshots are used)", 
            "title": "Caveats"
        }, 
        {
            "location": "/user-guide/storage-providers/#scaleio", 
            "text": "The ScaleIO driver registers a storage driver named  scaleio  with the libStorage  driver manager and is used to connect and manage ScaleIO storage.", 
            "title": "ScaleIO"
        }, 
        {
            "location": "/user-guide/storage-providers/#requirements", 
            "text": "The ScaleIO  REST Gateway  is required for the driver to function.  The  libStorage  client or application that embeds the  libStorage  client\n   must reside on a host that has the SDC client installed. The command\n    /opt/emc/scaleio/sdc/bin/drv_cfg --query_guid  should be executable and\n   should return the local SDC GUID.  The  official \n   Oracle Java Runtime Environment (JRE) is required. During testing, use of the\n   Open Java Development Kit (JDK) resulted in unexpected errors.", 
            "title": "Requirements"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration_1", 
            "text": "The following is an example with all possible fields configured.  For a running\nexample see the  Examples  section.  scaleio:\n  endpoint:             https://host_ip/api\n  apiVersion:            2.0 \n  insecure:             false\n  useCerts:             true\n  userName:             admin\n  password:             mypassword\n  systemID:             0\n  systemName:           sysv\n  protectionDomainID:   0\n  protectionDomainName: corp\n  storagePoolID:        0\n  storagePoolName:      gold\n  thinOrThick:          ThinProvisioned", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration-notes", 
            "text": "The  apiVersion  can optionally be set here to force certain API behavior.\nThe default is to retrieve the endpoint API, and pass this version during calls.  insecure  should be set to  true  if you have not loaded the SSL\ncertificates on the host.  A successful wget or curl should be possible without\nSSL errors to the API  endpoint  in this case.  useCerts  should only be set if you want to leverage the internal SSL\ncertificates.  This would be useful if you are deploying the REX-Ray binary\non a host that does not have any certificates installed.  systemID  takes priority over  systemName .  protectionDomainID  takes priority over  protectionDomainName .  storagePoolID  takes priority over  storagePoolName .  thinkOrThick  determines whether to provision as the default ThinProvisioned , or  ThickProvisioned .   For information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are transformed .", 
            "title": "Configuration Notes"
        }, 
        {
            "location": "/user-guide/storage-providers/#runtime-behavior", 
            "text": "The  storageType  field that is configured per volume is considered the\nScaleIO Storage Pool.  This can be configured by default with the  storagePool \nsetting.  It is important that you create unique names for your Storage Pools\non the same ScaleIO platform.  Otherwise, when specifying  storageType  it\nmay choose at random which  protectionDomain  the pool comes from.  The  availabilityZone  field represents the ScaleIO Protection Domain.", 
            "title": "Runtime Behavior"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuring-the-gateway", 
            "text": "Install the  EMC-ScaleIO-gateway  package.  Edit the /opt/emc/scaleio/gateway/webapps/ROOT/WEB-INF/classes/gatewayUser.properties \nfile and append the proper MDM IP addresses to the following  mdm.ip.addresses= \nparameter.  By default the password is the same as your administrative MDM password.  Start the gateway  service scaleio-gateway start .  With 1.32 we have noticed a restart of the gateway may be necessary as well\nafter an initial install with  service scaleio-gateway restart .", 
            "title": "Configuring the Gateway"
        }, 
        {
            "location": "/user-guide/storage-providers/#activating-the-driver_1", 
            "text": "To activate the ScaleIO driver please follow the instructions for activating storage drivers ,\nusing  scaleio  as the driver name.", 
            "title": "Activating the Driver"
        }, 
        {
            "location": "/user-guide/storage-providers/#troubleshooting", 
            "text": "Verify your parameters for  system ,  protectionDomain , and storagePool  are correct.  Verify that have the ScaleIO SDC service installed with rpm -qa EMC-ScaleIO-sdc  Verify that the following command returns the local SDC GUID /opt/emc/scaleio/sdc/bin/drv_cfg --query_guid .  Ensure that you are able to open a TCP connection to the gateway with the\naddress that you will be supplying below in the  gateway_ip  parameter.  For\nexample  telnet gateway_ip 443  should open a successful connection.  Removing\nthe  EMC-ScaleIO-gateway  package and reinstalling can force re-creation of\nself-signed certs which may help resolve gateway problems.  Also try restarting\nthe gateway with  service scaleio-gateway restart .  Ensure that you have the correct authentication credentials for the gateway.\nThis can be done with a curl login. You should receive an authentication\ntoken in return. curl --insecure --user admin:XScaleio123 https://gw_ip:443/api/login  Please review the gateway log at /opt/emc/scaleio/gateway/logs/catalina.out  for errors.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/user-guide/storage-providers/#examples_1", 
            "text": "Below is a full  config.yml  file that works with ScaleIO.  libstorage:\n  server:\n    services:\n      scaleio:\n        driver: scaleio\n        scaleio:\n          endpoint: https://gateway_ip/api\n          insecure: true\n          userName: username\n          password: password\n          systemName: tenantName\n          protectionDomainName: protectionDomainName\n          storagePoolName: storagePoolName", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/storage-providers/#virtualbox", 
            "text": "The VirtualBox driver registers a storage driver named  virtualbox  with the libStorage  driver manager and is used by VirtualBox's VMs to connect and\nmanage volumes provided by VirtualBox.", 
            "title": "VirtualBox"
        }, 
        {
            "location": "/user-guide/storage-providers/#prerequisites", 
            "text": "In order to leverage the  virtualbox  driver, the  libStorage  client or must\nbe located on each VM that you wish to be able to consume external volumes.\nThe driver leverages the  vboxwebserv  HTTP SOAP API which is a process that\nmust be started from the VirtualBox  host  (ie OS X) using vboxwebsrv -H 0.0.0.0 -v  or additionally with  -b  for running in the\nbackground. This allows the VMs running  libStorage  to remotely make calls to\nthe underlying VirtualBox application. A test for connectivity can be done with telnet virtualboxip 18083  from the VM. The  virtualboxip  is what you\nwould put in the  endpoint  value.  Leveraging authentication for the VirtualBox webserver is optiona.. The HTTP\nSOAP API can have authentication disabled by running VBoxManage setproperty websrvauthlibrary null .  Hot-Plugging is required, which limits the usefulness of this driver to  SATA \nonly.  Ensure that your VM has  pre-created  this controller and it is\nnamed  SATA .  Otherwise the  controllerName  field must be populated\nwith the name of the controller you wish to use.  The port count must be set\nmanually as it cannot be increased when the VMs are on.  A count of  30 \nis suggested.  VirtualBox 5.0.10+ must be used.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration_2", 
            "text": "The following is an example configuration of the VirtualBox driver. \nThe  localMachineNameOrId  parameter is for development use where you force libStorage  to use a specific VM identity.  Choose a  volumePath  to store the\nvolume files or virtual disks.  This path should be created ahead of time.  virtualbox:\n  endpoint: http://virtualboxhost:18083\n  userName: optional\n  password: optional\n  tls: false\n  volumePath: $HOME/VirtualBox/Volumes\n  controllerName: name\n  localMachineNameOrId: forDevelopmentUse  For information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are transformed .", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/storage-providers/#activating-the-driver_2", 
            "text": "To activate the VirtualBox driver please follow the instructions for activating storage drivers ,\nusing  virtualbox  as the driver name.", 
            "title": "Activating the Driver"
        }, 
        {
            "location": "/user-guide/storage-providers/#examples_2", 
            "text": "Below is a working  config.yml  file that works with VirtualBox.  libstorage:\n  server:\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/storage-providers/#caveats_1", 
            "text": "Snapshot and create volume from volume functionality is not available yet\n  with this driver.  The driver supports VirtualBox 5.0.10+", 
            "title": "Caveats"
        }, 
        {
            "location": "/user-guide/storage-providers/#aws-efs", 
            "text": "The AWS EFS driver registers a storage driver named  efs  with the libStorage  driver manager and is used to connect and manage AWS Elastic File\nSystems.", 
            "title": "AWS EFS"
        }, 
        {
            "location": "/user-guide/storage-providers/#requirements_1", 
            "text": "AWS account  VPC - EFS can be accessed within VPC  AWS Credentials", 
            "title": "Requirements"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration_3", 
            "text": "The following is an example with all possible fields configured.  For a running\nexample see the  Examples  section.  efs:\n  accessKey:      XXXXXXXXXX\n  secretKey:      XXXXXXXXXX\n  securityGroups: sg-XXXXXXX,sg-XXXXXX0,sg-XXXXXX1\n  region:         us-east-1\n  tag:            test", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/storage-providers/#configuration-notes_1", 
            "text": "The  accessKey  and  secretKey  configuration parameters are optional and should\nbe used when explicit AWS credentials configuration needs to be provided. EFS driver\nuses official golang AWS SDK library and supports all other ways of providing\naccess credentials, like environment variables or instance profile IAM permissions.  region  represents AWS region where should be EFS provisioned. See official AWS\ndocumentation for list of supported regions.  securityGroups  list of security groups attached to  MountPoint  instances.\nIf no security groups are provided the default VPC security group is used.  tag  is used to partition multiple services within single AWS account and is\nused as prefix for EFS names in format  [tagprefix]/volumeName .   For information on the equivalent environment variable and CLI flag names\nplease see the section on how non top-level configuration properties are transformed .", 
            "title": "Configuration Notes"
        }, 
        {
            "location": "/user-guide/storage-providers/#runtime-behavior_1", 
            "text": "AWS EFS storage driver creates one EFS FileSystem per volume and provides root\nof the filesystem as NFS mount point. Volumes aren't attached to instances\ndirectly but rather exposed to each subnet by creating  MountPoint  in each VPC\nsubnet. When detaching volume from instance no action is taken as there isn't\ngood way to figure out if there are other instances in same subnet using MountPoint  that is being detached. There is no charge for  MountPoint \nso they are removed only once whole volume is deleted.  By default all EFS instances are provisioned as  generalPurpose  performance mode. maxIO  EFS type can be provisioned by providing  maxIO  flag as  volumetype .  Its possible to mount same volume to multiple container on a single EC2 instance\nas well as use single volume across multiple EC2 instances at the same time.  NOTE : Each EFS FileSystem can be accessed only from single VPC at the time.", 
            "title": "Runtime Behavior"
        }, 
        {
            "location": "/user-guide/storage-providers/#activating-the-driver_3", 
            "text": "To activate the AWS EFS driver please follow the instructions for activating storage drivers ,\nusing  efs  as the driver name.", 
            "title": "Activating the Driver"
        }, 
        {
            "location": "/user-guide/storage-providers/#troubleshooting_1", 
            "text": "Make sure that AWS credentials (user or role) has following AWS permissions on\n   libStorage  server instance that will be making calls to AWS API:  elasticfilesystem:CreateFileSystem  elasticfilesystem:CreateMountTarget  ec2:DescribeSubnets  ec2:DescribeNetworkInterfaces  ec2:CreateNetworkInterface  elasticfilesystem:CreateTags  elasticfilesystem:DeleteFileSystem  elasticfilesystem:DeleteMountTarget  ec2:DeleteNetworkInterface  elasticfilesystem:DescribeFileSystems  elasticfilesystem:DescribeMountTargets", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/user-guide/storage-providers/#examples_3", 
            "text": "Below is a working  config.yml  file that works with AWS EFS.  libstorage:\n  server:\n    services:\n      efs:\n        driver: efs\n        efs:\n          accessKey:      XXXXXXXXXX\n          secretKey:      XXXXXXXXXX\n          securityGroups: sg-XXXXXXX,sg-XXXXXX0,sg-XXXXXX1\n          region:         us-east-1\n          tag:            test", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/schedulers/", 
            "text": "Schedulers\n\n\nScheduling storage one resource at a time...\n\n\n\n\nOverview\n\n\nThis page reviews the scheduling systems supported by \nlibStorage\n.\n\n\nDocker\n\n\nlibStorage\n's '\nDocker Integration Driver\n is compatible with 1.10+.\n\n\nHowever, \nDocker 1.10.2+\n is suggested if volumes are shared between containers\nor interactive volume inspection requests are desired via the \n/volumes\n,\n\n/volumes/{service}\n, and  \n/volumes/{service}/{volumeID}\n resources.\n\n\nPlease  note that this is \nnot\n the same as\n\nDocker's Volume Plug-in\n.\n\nlibStorage\n does not provide a way to expose the \nDocker Integration Driver\n\nvia the \nDocker Volume Plug-in\n, but \nREX-Ray\n, which embeds \nlibStorage\n,\ndoes.\n\n\nExample Configuration\n\n\nBelow is an example \nconfig.yml\n that can be used.  The \nvolume.mount.preempt\n\nis an optional parameter here which enables any host to take control of a\nvolume irrespective of whether other hosts are using the volume.  If this is\nset to \nfalse\n then plugins should ensure \nsafety\n first by locking the\nvolume from to the current owner host. We also specify \ndocker.size\n which will\ncreate all new volumes at the specified size in GB.\n\n\nlibstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  integration:\n    volume:\n      mount:\n        preempt: true\n      create:\n        default:\n          size: 1 # GB\n  server:\n    endpoints:\n      localhost:\n        address: unix:///var/run/libstorage/localhost.sock\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA\n\n\n\n\nConfiguration Properties\n\n\nThe Docker integration driver adheres to the properties described in the\nsection on an\n\nIntegration driver's volume-related properties\n.\n\n\nPlease note that with \nDocker\n 1.9.1 or below, it is recommended that the\nproperty \nlibstorage.integration.volume.remove.disable\n be set to \ntrue\n in\norder to prevent \nDocker\n from removing external volumes in-use by containers\nthat are forcefully removed.\n\n\nCaveats\n\n\nIf you restart the process which embeds \nlibStorage\n and hosts the\n\nDocker Volume Plug-in\n while volumes \nare shared between Docker containers\n,\nthen problems may arise when stopping one of the containers sharing the volume.\n\n\nIt is suggested to avoid stopping these containers at this point until all\ncontainers sharing the volumes can be stopped. This will enable the unmount\nprocess to proceed cleanly.", 
            "title": "Schedulers"
        }, 
        {
            "location": "/user-guide/schedulers/#schedulers", 
            "text": "Scheduling storage one resource at a time...", 
            "title": "Schedulers"
        }, 
        {
            "location": "/user-guide/schedulers/#overview", 
            "text": "This page reviews the scheduling systems supported by  libStorage .", 
            "title": "Overview"
        }, 
        {
            "location": "/user-guide/schedulers/#docker", 
            "text": "libStorage 's ' Docker Integration Driver  is compatible with 1.10+.  However,  Docker 1.10.2+  is suggested if volumes are shared between containers\nor interactive volume inspection requests are desired via the  /volumes , /volumes/{service} , and   /volumes/{service}/{volumeID}  resources.  Please  note that this is  not  the same as Docker's Volume Plug-in . libStorage  does not provide a way to expose the  Docker Integration Driver \nvia the  Docker Volume Plug-in , but  REX-Ray , which embeds  libStorage ,\ndoes.", 
            "title": "Docker"
        }, 
        {
            "location": "/user-guide/schedulers/#example-configuration", 
            "text": "Below is an example  config.yml  that can be used.  The  volume.mount.preempt \nis an optional parameter here which enables any host to take control of a\nvolume irrespective of whether other hosts are using the volume.  If this is\nset to  false  then plugins should ensure  safety  first by locking the\nvolume from to the current owner host. We also specify  docker.size  which will\ncreate all new volumes at the specified size in GB.  libstorage:\n  host: unix:///var/run/libstorage/localhost.sock\n  integration:\n    volume:\n      mount:\n        preempt: true\n      create:\n        default:\n          size: 1 # GB\n  server:\n    endpoints:\n      localhost:\n        address: unix:///var/run/libstorage/localhost.sock\n    services:\n      virtualbox:\n        driver: virtualbox\n        virtualbox:\n          endpoint:       http://10.0.2.2:18083\n          tls:            false\n          volumePath:     $HOME/VirtualBox/Volumes\n          controllerName: SATA", 
            "title": "Example Configuration"
        }, 
        {
            "location": "/user-guide/schedulers/#configuration-properties", 
            "text": "The Docker integration driver adheres to the properties described in the\nsection on an Integration driver's volume-related properties .  Please note that with  Docker  1.9.1 or below, it is recommended that the\nproperty  libstorage.integration.volume.remove.disable  be set to  true  in\norder to prevent  Docker  from removing external volumes in-use by containers\nthat are forcefully removed.", 
            "title": "Configuration Properties"
        }, 
        {
            "location": "/user-guide/schedulers/#caveats", 
            "text": "If you restart the process which embeds  libStorage  and hosts the Docker Volume Plug-in  while volumes  are shared between Docker containers ,\nthen problems may arise when stopping one of the containers sharing the volume.  It is suggested to avoid stopping these containers at this point until all\ncontainers sharing the volumes can be stopped. This will enable the unmount\nprocess to proceed cleanly.", 
            "title": "Caveats"
        }, 
        {
            "location": "/dev-guide/project-guidelines/", 
            "text": "Project Guidelines\n\n\nThese are important.\n\n\n\n\nPeople contributing code to this project must adhere to the following rules.\nThese standards are in place to keep code clean, consistent, and stable.\n\n\nDocumentation\n\n\nThere are two types of documentation: source and markdown.\n\n\nSource Code\n\n\nAll source code should be documented in accordance with the\n\nGo's documentation rules\n.\n\n\nMarkdown\n\n\nWhen creating or modifying the project's \nREADME.md\n file or any of the\ndocumentation in the \n.docs\n directory, please keep the following rules in\nmind:\n\n\n\n\nAll links to internal resources should be relative.\n\n\nAll links to markdown files should include the file extension.\n\n\n\n\nFor example, the below link points to the anchor \nbasic-configuration\n on the\n\nConfiguration\n page:\n\n\n\n\n/user-guide/config#basic-configuration\n\n\nHowever, when the above link is followed when viewing this page directly from\nthe Github repository instead of the generated site documentation, the link\nwill return a 404.\n\n\nWhile it's recommended that users view the generated site documentation instead\nof the source Markdown directly, we can still fix it so that the above link\nwill work regardless. To fix the link, simply make it relative and add the\nMarkdown file extension:\n\n\n\n\n../user-guide/config.md#basic-configuration\n\n\nNow the link will work regardless from where it's viewed.\n\n\nStyle \n Syntax\n\n\nAll source files should be processed by the\n\ngometalinter\n before committed. Any\nerrors or warnings produced by the tools should be corrected before the source\nis committed.\n\n\nIf \nAtom\n is your IDE of choice, install the\n\ngo-plus\n package, and it will execute the\ngometalinter every time a source file is saved.\n\n\nIn lieu of using Atom as the IDE, the project's \nMakefile\n automatically\nexecutes the above tools as part of the build process and will fail the build\nif problems are discovered.\n\n\nCode Coverage\n\n\nAll new work submitted to the project should have associated tests where\napplicable. If there is ever a question of whether or not a test is applicable\nthen the answer is likely yes.\n\n\nThis project uses\n\nCodecov\n for code coverage, and\nall pull requests are processed just as a build from \nmaster\n. If a pull request\ndecreases the project's code coverage, the pull request will be declined until\nsuch time that testing is added or enhanced to compensate.\n\n\nCommit Messages\n\n\nCommit messages should follow the guide \n5 Useful Tips For a Better Commit\nMessage\n.\nThe two primary rules to which to adhere are:\n\n\n\n\n\n\nCommit message subjects should not exceed 50 characters in total and\n     should be followed by a blank line.\n\n\n\n\n\n\nThe commit message's body should not have a width that exceeds 72\n     characters.\n\n\n\n\n\n\nFor example, the following commit has a very useful message that is succinct\nwithout losing utility.\n\n\ncommit e80c696939a03f26cd180934ba642a729b0d2941\nAuthor: akutz \nsakutz@gmail.com\n\nDate:   Tue Oct 20 23:47:36 2015 -0500\n\n    Added --format,-f option for CLI\n\n    This patch adds the flag '--format' or '-f' for the\n    following CLI commands:\n\n        * adapter instances\n        * device [get]\n        * snapshot [get]\n        * snapshot copy\n        * snapshot create\n        * volume [get]\n        * volume attach\n        * volume create\n        * volume map\n        * volume mount\n        * volume path\n\n    The user can specify either '--format=yml|yaml|json' or\n    '-f yml|yaml|json' in order to influence how the resulting,\n    structured data is marshaled prior to being emitted to the console.\n\n\n\n\nPlease note that the output above is the full output for viewing a commit.\nHowever, because the above message adheres to the commit message rules, it's\nquite easy to show just the commit's subject:\n\n\n$ git show e80c696939a03f26cd180934ba642a729b0d2941 --format=\n%s\n -s\nAdded --format,-f option for CLI\n\n\n\n\nIt's also equally simple to print the commit's subject and body together:\n\n\n$ git show e80c696939a03f26cd180934ba642a729b0d2941 --format=\n%s%n%n%b\n -s\nAdded --format,-f option for CLI\n\nThis patch adds the flag '--format' or '-f' for the\nfollowing CLI commands:\n\n    * adapter instances\n    * device [get]\n    * snapshot [get]\n    * snapshot copy\n    * snapshot create\n    * volume [get]\n    * volume attach\n    * volume create\n    * volume map\n    * volume mount\n    * volume path\n\nThe user can specify either '--format=yml|yaml|json' or\n'-f yml|yaml|json' in order to influence how the resulting,\nstructured data is marshaled prior to being emitted to the console.\n\n\n\n\nSubmitting Changes\n\n\nAll developers are required to follow the\n\nGitHub Flow model\n when\nproposing new features or even submitting fixes.\n\n\nPlease note that although not explicitly stated in the referenced GitHub Flow\nmodel, all work should occur on a \nfork\n of this project, not from within a\nbranch of this project itself.\n\n\nPull requests submitted to this project should adhere to the following\nguidelines:\n\n\n\n\n\n\nBranches should be rebased off of the upstream master prior to being\n    opened as pull requests and again prior to merge. This is to ensure that\n    the build system accounts for any changes that may only be detected during\n    the build and test phase.\n\n\n\n\n\n\nUnless granted an exception a pull request should contain only a single\n    commit. This is because features and patches should be atomic -- wholly\n    shippable items that are either included in a release, or not. Please\n    squash commits on a branch before opening a pull request. It is not a\n    deal-breaker otherwise, but please be prepared to add a comment or\n    explanation as to why you feel multiple commits are required.", 
            "title": "Project Guidelines"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#project-guidelines", 
            "text": "These are important.   People contributing code to this project must adhere to the following rules.\nThese standards are in place to keep code clean, consistent, and stable.", 
            "title": "Project Guidelines"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#documentation", 
            "text": "There are two types of documentation: source and markdown.", 
            "title": "Documentation"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#source-code", 
            "text": "All source code should be documented in accordance with the Go's documentation rules .", 
            "title": "Source Code"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#markdown", 
            "text": "When creating or modifying the project's  README.md  file or any of the\ndocumentation in the  .docs  directory, please keep the following rules in\nmind:   All links to internal resources should be relative.  All links to markdown files should include the file extension.   For example, the below link points to the anchor  basic-configuration  on the Configuration  page:   /user-guide/config#basic-configuration  However, when the above link is followed when viewing this page directly from\nthe Github repository instead of the generated site documentation, the link\nwill return a 404.  While it's recommended that users view the generated site documentation instead\nof the source Markdown directly, we can still fix it so that the above link\nwill work regardless. To fix the link, simply make it relative and add the\nMarkdown file extension:   ../user-guide/config.md#basic-configuration  Now the link will work regardless from where it's viewed.", 
            "title": "Markdown"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#style-syntax", 
            "text": "All source files should be processed by the gometalinter  before committed. Any\nerrors or warnings produced by the tools should be corrected before the source\nis committed.  If  Atom  is your IDE of choice, install the go-plus  package, and it will execute the\ngometalinter every time a source file is saved.  In lieu of using Atom as the IDE, the project's  Makefile  automatically\nexecutes the above tools as part of the build process and will fail the build\nif problems are discovered.", 
            "title": "Style &amp; Syntax"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#code-coverage", 
            "text": "All new work submitted to the project should have associated tests where\napplicable. If there is ever a question of whether or not a test is applicable\nthen the answer is likely yes.  This project uses Codecov  for code coverage, and\nall pull requests are processed just as a build from  master . If a pull request\ndecreases the project's code coverage, the pull request will be declined until\nsuch time that testing is added or enhanced to compensate.", 
            "title": "Code Coverage"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#commit-messages", 
            "text": "Commit messages should follow the guide  5 Useful Tips For a Better Commit\nMessage .\nThe two primary rules to which to adhere are:    Commit message subjects should not exceed 50 characters in total and\n     should be followed by a blank line.    The commit message's body should not have a width that exceeds 72\n     characters.    For example, the following commit has a very useful message that is succinct\nwithout losing utility.  commit e80c696939a03f26cd180934ba642a729b0d2941\nAuthor: akutz  sakutz@gmail.com \nDate:   Tue Oct 20 23:47:36 2015 -0500\n\n    Added --format,-f option for CLI\n\n    This patch adds the flag '--format' or '-f' for the\n    following CLI commands:\n\n        * adapter instances\n        * device [get]\n        * snapshot [get]\n        * snapshot copy\n        * snapshot create\n        * volume [get]\n        * volume attach\n        * volume create\n        * volume map\n        * volume mount\n        * volume path\n\n    The user can specify either '--format=yml|yaml|json' or\n    '-f yml|yaml|json' in order to influence how the resulting,\n    structured data is marshaled prior to being emitted to the console.  Please note that the output above is the full output for viewing a commit.\nHowever, because the above message adheres to the commit message rules, it's\nquite easy to show just the commit's subject:  $ git show e80c696939a03f26cd180934ba642a729b0d2941 --format= %s  -s\nAdded --format,-f option for CLI  It's also equally simple to print the commit's subject and body together:  $ git show e80c696939a03f26cd180934ba642a729b0d2941 --format= %s%n%n%b  -s\nAdded --format,-f option for CLI\n\nThis patch adds the flag '--format' or '-f' for the\nfollowing CLI commands:\n\n    * adapter instances\n    * device [get]\n    * snapshot [get]\n    * snapshot copy\n    * snapshot create\n    * volume [get]\n    * volume attach\n    * volume create\n    * volume map\n    * volume mount\n    * volume path\n\nThe user can specify either '--format=yml|yaml|json' or\n'-f yml|yaml|json' in order to influence how the resulting,\nstructured data is marshaled prior to being emitted to the console.", 
            "title": "Commit Messages"
        }, 
        {
            "location": "/dev-guide/project-guidelines/#submitting-changes", 
            "text": "All developers are required to follow the GitHub Flow model  when\nproposing new features or even submitting fixes.  Please note that although not explicitly stated in the referenced GitHub Flow\nmodel, all work should occur on a  fork  of this project, not from within a\nbranch of this project itself.  Pull requests submitted to this project should adhere to the following\nguidelines:    Branches should be rebased off of the upstream master prior to being\n    opened as pull requests and again prior to merge. This is to ensure that\n    the build system accounts for any changes that may only be detected during\n    the build and test phase.    Unless granted an exception a pull request should contain only a single\n    commit. This is because features and patches should be atomic -- wholly\n    shippable items that are either included in a release, or not. Please\n    squash commits on a branch before opening a pull request. It is not a\n    deal-breaker otherwise, but please be prepared to add a comment or\n    explanation as to why you feel multiple commits are required.", 
            "title": "Submitting Changes"
        }, 
        {
            "location": "/dev-guide/build-reference/", 
            "text": "Build Reference\n\n\nHow to build libStorage\n\n\n\n\nBuild Requirements\n\n\nThis project has very few build requirements, but there are still one or two\nitems of which to be aware. Also, please note that this are the requirements to\n\nbuild\n \nlibStorage\n, not run it.\n\n\n\n\n\n\n\n\nRequirement\n\n\nVersion\n\n\n\n\n\n\n\n\n\n\nOperating System\n\n\nLinux, OS X\n\n\n\n\n\n\nGo\n\n\n=1.6\n\n\n\n\n\n\nGNU Make\n\n\n=3.80\n\n\n\n\n\n\nGlide\n\n\n=0.10\n\n\n\n\n\n\nX-Code Command Line Tools (OS X only)\n\n\n= OS X 10.9\n\n\n\n\n\n\nLinux Kernel Headers (Linux only)\n\n\n=Linux Kernel 3.13\n\n\n\n\n\n\nGNU C Compiler\n (Linux only)\n\n\n= 4.8\n\n\n\n\n\n\n\n\nOS X ships with a very old version of GNU Make, and a package manager like\n\nHomebrew\n can be used to install the required version.\n\n\nIt's also possible to use GCC as the Cgo compiler for OS X or to use Clang on\nLinux, but by default Clang is used on OS X and GCC on Linux.\n\n\nCross-Compilation\n\n\nThis project's\n\nMakefile\n\nis configured by default to cross-compile certain project components for both\nLinux x86_64 and Darwin (OS X) x86_64. Therefore the build process will fail if\nthe local Go environment is not configured for cross-compilation. Please take a\nminute to read this\n\nblog post\n\nregarding cross-compilation with Go \n=1.5.\n\n\nWhile \nsome\n of this project's components are cross-compiled as part of a\nstandard build, the project as a whole is not. This is because the project\nhas key components that are dependent upon the Cgo compiler, and most build\nsystems do not possess the capability to cross-compile against the C stdlib\ntool-chain.\n\n\nBasic Build\n\n\nBuilding from source should be fairly straight-forward as the most basic build\ncan be achieved by executing \nmake\n from the project's root directory.\n\n\n$ make\nmake deps\nmake[1]: Entering directory './github.com/emccode/libstorage'\nglide up \n touch glide.lock.d\n[INFO] Downloading dependencies. Please wait...\n[INFO] Fetching updates for github.com/Sirupsen/logrus.\n[INFO] Fetching updates for github.com/stretchr/testify.\n[INFO] Fetching updates for github.com/akutz/golf.\n[INFO] Fetching updates for github.com/akutz/gofig.\n[INFO] Fetching updates for github.com/appropriate/go-virtualboxclient.\n[INFO] Fetching updates for github.com/jteeuwen/go-bindata.\n[INFO] Fetching updates for github.com/emccode/goisilon.\n[INFO] Fetching updates for github.com/blang/semver.\n[INFO] Fetching updates for github.com/cesanta/validate-json.\n[INFO] Fetching updates for github.com/akutz/goof.\n[INFO] Fetching updates for github.com/emccode/goscaleio.\n[INFO] Fetching updates for github.com/akutz/gotil.\n[INFO] Setting version for github.com/Sirupsen/logrus to feature/logrus-aware-types.\n[INFO] Setting version for github.com/blang/semver to v3.0.1.\n[INFO] Setting version for github.com/jteeuwen/go-bindata to feature/md5checksum.\n[INFO] Setting version for github.com/emccode/goscaleio to 53ea76f52205380ab52b9c1f4ad89321c286bb95.\n[INFO] Setting version for github.com/emccode/goisilon to f9b53f0aaadb12a26b134830142fc537f492cb13.\n[INFO] Setting version for github.com/appropriate/go-virtualboxclient to e0978ab2ed407095400a69d5933958dd260058cd.\n[INFO] Resolving imports\n[INFO] Setting version for github.com/akutz/goof to master.\n[INFO] Setting version for github.com/akutz/gotil to master.\n[INFO] Fetching updates for github.com/spf13/pflag.\n[INFO] Setting version for github.com/spf13/pflag to b084184666e02084b8ccb9b704bf0d79c466eb1d.\n[INFO] Fetching updates for github.com/spf13/viper.\n[INFO] Setting version for github.com/spf13/viper to support/rexray.\n[INFO] Fetching updates for gopkg.in/yaml.v2.\n[INFO] Setting version for gopkg.in/yaml.v2 to b4a9f8c4b84c6c4256d669c649837f1441e4b050.\n[INFO] Fetching updates for golang.org/x/sys.\n[INFO] Fetching updates for github.com/kardianos/osext.\n[INFO] Setting version for github.com/kardianos/osext to master.\n[INFO] Fetching updates for golang.org/x/net.\n[INFO] Found Godeps.json file in vendor/github.com/stretchr/testify\n[INFO] Fetching updates for github.com/davecgh/go-spew.\n[INFO] Setting version for github.com/davecgh/go-spew to 5215b55f46b2b919f50a1df0eaa5886afe4e3b3d.\n[INFO] Fetching updates for github.com/pmezard/go-difflib.\n[INFO] Setting version for github.com/pmezard/go-difflib to d8ed2627bdf02c080bf22230dbb337003b7aba2d.\n[INFO] Fetching updates for github.com/asaskevich/govalidator.\n[INFO] Fetching updates for github.com/BurntSushi/toml.\n[INFO] Fetching updates for github.com/kr/pretty.\n[INFO] Fetching updates for github.com/magiconair/properties.\n[INFO] Fetching updates for github.com/mitchellh/mapstructure.\n[INFO] Fetching updates for github.com/spf13/cast.\n[INFO] Fetching updates for github.com/spf13/jwalterweatherman.\n[INFO] Fetching updates for gopkg.in/fsnotify.v1.\n[INFO] Fetching updates for github.com/kr/text.\n[INFO] Downloading dependencies. Please wait...\n[INFO] Fetching updates for github.com/gorilla/mux.\n[INFO] Fetching updates for github.com/cesanta/ucl.\n[INFO] Fetching updates for github.com/gorilla/context.\n[INFO] Setting references for remaining imports\n[INFO] Project relies on 32 dependencies.\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\nmake[1]: Leaving directory './github.com/emccode/libstorage'\nmake build\nmake[1]: Entering directory './github.com/emccode/libstorage'\ngcc -Wall -pedantic -std=c99 cli/semaphores/open.c -o cli/semaphores/open -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/wait.c -o cli/semaphores/wait -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/signal.c -o cli/semaphores/signal -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/unlink.c -o cli/semaphores/unlink -lpthread\ngo install ./api/types\ngo install ./api/context\ngo install ./api/utils\ngo install ./api/registry\ngo install ./api/utils/schema\ngo install ./api/server/services\ngo install ./api/server/httputils\ngo install ./api/server/handlers\ngo install ./api/utils/paths\ngo install ./api/utils/config\ngo install ./api/utils/semaphore\ngo install ./drivers/storage/isilon\ngo install ./drivers/storage/isilon/storage\ngo install ./drivers/storage/scaleio\ngo install ./drivers/storage/scaleio/storage\ngo install ./drivers/storage/vbox\ngo install ./drivers/storage/vbox/storage\ngo install ./drivers/storage/vfs\ngo install ./drivers/storage/vfs/storage\ngo install ./imports/remote\nenv GOOS=linux GOARCH=amd64 make -j $GOPATH/bin/linux_amd64/lsx-linux\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo install ./api/types\ngo install ./drivers/storage/isilon\ngo install ./api/context\ngo install ./api/utils\ngo install ./api/registry\ngo install ./api/utils/config\ngo install ./drivers/storage/isilon/executor\ngo install ./drivers/storage/scaleio/executor\ngo install ./drivers/storage/vbox/executor\ngo install ./drivers/storage/vfs/executor\ngo install ./imports/executors\ngo install ./cli/lsx\ngo install ./cli/lsx/lsx-linux\nmake[2]: Leaving directory './github.com/emccode/libstorage'\ngo install ./imports/config\ngo install ./drivers/storage/isilon/executor\ngo install ./drivers/storage/scaleio/executor\ngo install ./drivers/storage/vbox/executor\ngo install ./drivers/storage/vfs/executor\ngo install ./imports/executors\ngo install ./cli/lsx\ngo install ./cli/lsx/lsx-darwin\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\n$GOPATH/bin/go-bindata -md5checksum -pkg executors -prefix api/server/executors/bin -o api/server/executors/executors_generated.go api/server/executors/bin/...\ngo install ./api/server/executors\ngo install ./api/server/router/executor\ngo install ./api/server/router/root\ngo install ./api/server/router/service\ngo install ./api/utils/filters\ngo install ./api/server/router/volume\ngo install ./api/server/router/snapshot\ngo install ./api/server/router/tasks\ngo install ./imports/routers\ngo install ./api/server\ngo install ./drivers/integration/docker\ngo install ./drivers/os/darwin\ngo install ./drivers/os/linux\ngo install ./api/client\ngo install ./drivers/storage/libstorage\ngo install ./drivers/storage/vfs/client\ngo install ./imports/local\ngo install ./client\ngo install .\ngo install ./api\ngo install ./api/server/router\ngo install ./api/tests\ngo install ./cli/lss\ngo install ./cli/lss/lss-darwin\ngo install ./drivers/storage/vbox/client\nmake -j libstor-c libstor-s\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo build -buildmode=c-shared -o $GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/libstor-c.so ./c/libstor-c\ngo install ./drivers/storage/isilon/storage\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\ngo build -buildmode=c-shared -o $GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/libstor-s.so ./c/libstor-s\ngcc -Wall -pedantic -std=c99 -I$GOPATH/src/github.com/emccode/libstorage/c/libstor-c \\\n          -I$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -L$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -o $GOPATH/bin/libstor-c \\\n          ./c/libstor-c.c \\\n          -lstor-c\ngcc -Wall -pedantic -std=c99 -I$GOPATH/src/github.com/emccode/libstorage/c \\\n          -I$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -L$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -o $GOPATH/bin/libstor-s \\\n          ./c/libstor-s.c \\\n          -lstor-s\nmake[2]: Leaving directory './github.com/emccode/libstorage'\nmake build-lss\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo install ./drivers/storage/isilon/storage\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\nmake[2]: Leaving directory './github.com/emccode/libstorage'\nmake[1]: Leaving directory './github.com/emccode/libstorage'\n\n\n\n\nVersion File\n\n\nThere is a file at the root of the project named \nVERSION\n. The file contains\na single line with the \ntarget\n version of the project in the file. The version\nfollows the format:\n\n\n(?\nmajor\n\\d+)\\.(?\nminor\n\\d+)\\.(?\npatch\n\\d+)(-rc\\d+)?\n\n\nFor example, during active development of version \n0.1.0\n the file would\ncontain the version \n0.1.0\n. When it's time to create \n0.1.0\n's first\nrelease candidate the version in the file will be changed to \n0.1.0-rc1\n. And\nwhen it's time to release \n0.1.0\n the version is changed back to \n0.1.0\n.\n\n\nSo what's the point of the file if it's basically duplicating the utility of a\ntag? Well, the \nVERSION\n file in fact has two purposes:\n\n\n\n\n\n\nFirst and foremost updating the \nVERSION\n file with the same value as that\n     of the tag used to create a release provides a single, contextual reason to\n     push a commit and tag. Otherwise some random commit off of \nmaster\n would\n     be tagged as a release candidate or release. Always using the commit that\n     is related to updating the \nVERSION\n file is much cleaner.\n\n\n\n\n\n\nThe contents of the \nVERSION\n file are also used during the build process\n     as a means of overriding the output of a \ngit describe\n. This enables the\n     semantic version injected into the produced binary to be created using\n     the \ntargeted\n version of the next release and not just the value of the\n     last, tagged commit.", 
            "title": "Build Reference"
        }, 
        {
            "location": "/dev-guide/build-reference/#build-reference", 
            "text": "How to build libStorage", 
            "title": "Build Reference"
        }, 
        {
            "location": "/dev-guide/build-reference/#build-requirements", 
            "text": "This project has very few build requirements, but there are still one or two\nitems of which to be aware. Also, please note that this are the requirements to build   libStorage , not run it.     Requirement  Version      Operating System  Linux, OS X    Go  =1.6    GNU Make  =3.80    Glide  =0.10    X-Code Command Line Tools (OS X only)  = OS X 10.9    Linux Kernel Headers (Linux only)  =Linux Kernel 3.13    GNU C Compiler  (Linux only)  = 4.8     OS X ships with a very old version of GNU Make, and a package manager like Homebrew  can be used to install the required version.  It's also possible to use GCC as the Cgo compiler for OS X or to use Clang on\nLinux, but by default Clang is used on OS X and GCC on Linux.", 
            "title": "Build Requirements"
        }, 
        {
            "location": "/dev-guide/build-reference/#cross-compilation", 
            "text": "This project's Makefile \nis configured by default to cross-compile certain project components for both\nLinux x86_64 and Darwin (OS X) x86_64. Therefore the build process will fail if\nthe local Go environment is not configured for cross-compilation. Please take a\nminute to read this blog post \nregarding cross-compilation with Go  =1.5.  While  some  of this project's components are cross-compiled as part of a\nstandard build, the project as a whole is not. This is because the project\nhas key components that are dependent upon the Cgo compiler, and most build\nsystems do not possess the capability to cross-compile against the C stdlib\ntool-chain.", 
            "title": "Cross-Compilation"
        }, 
        {
            "location": "/dev-guide/build-reference/#basic-build", 
            "text": "Building from source should be fairly straight-forward as the most basic build\ncan be achieved by executing  make  from the project's root directory.  $ make\nmake deps\nmake[1]: Entering directory './github.com/emccode/libstorage'\nglide up   touch glide.lock.d\n[INFO] Downloading dependencies. Please wait...\n[INFO] Fetching updates for github.com/Sirupsen/logrus.\n[INFO] Fetching updates for github.com/stretchr/testify.\n[INFO] Fetching updates for github.com/akutz/golf.\n[INFO] Fetching updates for github.com/akutz/gofig.\n[INFO] Fetching updates for github.com/appropriate/go-virtualboxclient.\n[INFO] Fetching updates for github.com/jteeuwen/go-bindata.\n[INFO] Fetching updates for github.com/emccode/goisilon.\n[INFO] Fetching updates for github.com/blang/semver.\n[INFO] Fetching updates for github.com/cesanta/validate-json.\n[INFO] Fetching updates for github.com/akutz/goof.\n[INFO] Fetching updates for github.com/emccode/goscaleio.\n[INFO] Fetching updates for github.com/akutz/gotil.\n[INFO] Setting version for github.com/Sirupsen/logrus to feature/logrus-aware-types.\n[INFO] Setting version for github.com/blang/semver to v3.0.1.\n[INFO] Setting version for github.com/jteeuwen/go-bindata to feature/md5checksum.\n[INFO] Setting version for github.com/emccode/goscaleio to 53ea76f52205380ab52b9c1f4ad89321c286bb95.\n[INFO] Setting version for github.com/emccode/goisilon to f9b53f0aaadb12a26b134830142fc537f492cb13.\n[INFO] Setting version for github.com/appropriate/go-virtualboxclient to e0978ab2ed407095400a69d5933958dd260058cd.\n[INFO] Resolving imports\n[INFO] Setting version for github.com/akutz/goof to master.\n[INFO] Setting version for github.com/akutz/gotil to master.\n[INFO] Fetching updates for github.com/spf13/pflag.\n[INFO] Setting version for github.com/spf13/pflag to b084184666e02084b8ccb9b704bf0d79c466eb1d.\n[INFO] Fetching updates for github.com/spf13/viper.\n[INFO] Setting version for github.com/spf13/viper to support/rexray.\n[INFO] Fetching updates for gopkg.in/yaml.v2.\n[INFO] Setting version for gopkg.in/yaml.v2 to b4a9f8c4b84c6c4256d669c649837f1441e4b050.\n[INFO] Fetching updates for golang.org/x/sys.\n[INFO] Fetching updates for github.com/kardianos/osext.\n[INFO] Setting version for github.com/kardianos/osext to master.\n[INFO] Fetching updates for golang.org/x/net.\n[INFO] Found Godeps.json file in vendor/github.com/stretchr/testify\n[INFO] Fetching updates for github.com/davecgh/go-spew.\n[INFO] Setting version for github.com/davecgh/go-spew to 5215b55f46b2b919f50a1df0eaa5886afe4e3b3d.\n[INFO] Fetching updates for github.com/pmezard/go-difflib.\n[INFO] Setting version for github.com/pmezard/go-difflib to d8ed2627bdf02c080bf22230dbb337003b7aba2d.\n[INFO] Fetching updates for github.com/asaskevich/govalidator.\n[INFO] Fetching updates for github.com/BurntSushi/toml.\n[INFO] Fetching updates for github.com/kr/pretty.\n[INFO] Fetching updates for github.com/magiconair/properties.\n[INFO] Fetching updates for github.com/mitchellh/mapstructure.\n[INFO] Fetching updates for github.com/spf13/cast.\n[INFO] Fetching updates for github.com/spf13/jwalterweatherman.\n[INFO] Fetching updates for gopkg.in/fsnotify.v1.\n[INFO] Fetching updates for github.com/kr/text.\n[INFO] Downloading dependencies. Please wait...\n[INFO] Fetching updates for github.com/gorilla/mux.\n[INFO] Fetching updates for github.com/cesanta/ucl.\n[INFO] Fetching updates for github.com/gorilla/context.\n[INFO] Setting references for remaining imports\n[INFO] Project relies on 32 dependencies.\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\nmake[1]: Leaving directory './github.com/emccode/libstorage'\nmake build\nmake[1]: Entering directory './github.com/emccode/libstorage'\ngcc -Wall -pedantic -std=c99 cli/semaphores/open.c -o cli/semaphores/open -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/wait.c -o cli/semaphores/wait -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/signal.c -o cli/semaphores/signal -lpthread\ngcc -Wall -pedantic -std=c99 cli/semaphores/unlink.c -o cli/semaphores/unlink -lpthread\ngo install ./api/types\ngo install ./api/context\ngo install ./api/utils\ngo install ./api/registry\ngo install ./api/utils/schema\ngo install ./api/server/services\ngo install ./api/server/httputils\ngo install ./api/server/handlers\ngo install ./api/utils/paths\ngo install ./api/utils/config\ngo install ./api/utils/semaphore\ngo install ./drivers/storage/isilon\ngo install ./drivers/storage/isilon/storage\ngo install ./drivers/storage/scaleio\ngo install ./drivers/storage/scaleio/storage\ngo install ./drivers/storage/vbox\ngo install ./drivers/storage/vbox/storage\ngo install ./drivers/storage/vfs\ngo install ./drivers/storage/vfs/storage\ngo install ./imports/remote\nenv GOOS=linux GOARCH=amd64 make -j $GOPATH/bin/linux_amd64/lsx-linux\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo install ./api/types\ngo install ./drivers/storage/isilon\ngo install ./api/context\ngo install ./api/utils\ngo install ./api/registry\ngo install ./api/utils/config\ngo install ./drivers/storage/isilon/executor\ngo install ./drivers/storage/scaleio/executor\ngo install ./drivers/storage/vbox/executor\ngo install ./drivers/storage/vfs/executor\ngo install ./imports/executors\ngo install ./cli/lsx\ngo install ./cli/lsx/lsx-linux\nmake[2]: Leaving directory './github.com/emccode/libstorage'\ngo install ./imports/config\ngo install ./drivers/storage/isilon/executor\ngo install ./drivers/storage/scaleio/executor\ngo install ./drivers/storage/vbox/executor\ngo install ./drivers/storage/vfs/executor\ngo install ./imports/executors\ngo install ./cli/lsx\ngo install ./cli/lsx/lsx-darwin\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\n$GOPATH/bin/go-bindata -md5checksum -pkg executors -prefix api/server/executors/bin -o api/server/executors/executors_generated.go api/server/executors/bin/...\ngo install ./api/server/executors\ngo install ./api/server/router/executor\ngo install ./api/server/router/root\ngo install ./api/server/router/service\ngo install ./api/utils/filters\ngo install ./api/server/router/volume\ngo install ./api/server/router/snapshot\ngo install ./api/server/router/tasks\ngo install ./imports/routers\ngo install ./api/server\ngo install ./drivers/integration/docker\ngo install ./drivers/os/darwin\ngo install ./drivers/os/linux\ngo install ./api/client\ngo install ./drivers/storage/libstorage\ngo install ./drivers/storage/vfs/client\ngo install ./imports/local\ngo install ./client\ngo install .\ngo install ./api\ngo install ./api/server/router\ngo install ./api/tests\ngo install ./cli/lss\ngo install ./cli/lss/lss-darwin\ngo install ./drivers/storage/vbox/client\nmake -j libstor-c libstor-s\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo build -buildmode=c-shared -o $GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/libstor-c.so ./c/libstor-c\ngo install ./drivers/storage/isilon/storage\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\ngo build -buildmode=c-shared -o $GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/libstor-s.so ./c/libstor-s\ngcc -Wall -pedantic -std=c99 -I$GOPATH/src/github.com/emccode/libstorage/c/libstor-c \\\n          -I$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -L$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -o $GOPATH/bin/libstor-c \\\n          ./c/libstor-c.c \\\n          -lstor-c\ngcc -Wall -pedantic -std=c99 -I$GOPATH/src/github.com/emccode/libstorage/c \\\n          -I$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -L$GOPATH/pkg/darwin_amd64/github.com/emccode/libstorage/c/ \\\n          -o $GOPATH/bin/libstor-s \\\n          ./c/libstor-s.c \\\n          -lstor-s\nmake[2]: Leaving directory './github.com/emccode/libstorage'\nmake build-lss\nmake[2]: Entering directory './github.com/emccode/libstorage'\ngo install ./drivers/storage/isilon/storage\ngo install github.com/emccode/libstorage/vendor/github.com/jteeuwen/go-bindata/go-bindata\nmake[2]: Leaving directory './github.com/emccode/libstorage'\nmake[1]: Leaving directory './github.com/emccode/libstorage'", 
            "title": "Basic Build"
        }, 
        {
            "location": "/dev-guide/build-reference/#version-file", 
            "text": "There is a file at the root of the project named  VERSION . The file contains\na single line with the  target  version of the project in the file. The version\nfollows the format:  (? major \\d+)\\.(? minor \\d+)\\.(? patch \\d+)(-rc\\d+)?  For example, during active development of version  0.1.0  the file would\ncontain the version  0.1.0 . When it's time to create  0.1.0 's first\nrelease candidate the version in the file will be changed to  0.1.0-rc1 . And\nwhen it's time to release  0.1.0  the version is changed back to  0.1.0 .  So what's the point of the file if it's basically duplicating the utility of a\ntag? Well, the  VERSION  file in fact has two purposes:    First and foremost updating the  VERSION  file with the same value as that\n     of the tag used to create a release provides a single, contextual reason to\n     push a commit and tag. Otherwise some random commit off of  master  would\n     be tagged as a release candidate or release. Always using the commit that\n     is related to updating the  VERSION  file is much cleaner.    The contents of the  VERSION  file are also used during the build process\n     as a means of overriding the output of a  git describe . This enables the\n     semantic version injected into the produced binary to be created using\n     the  targeted  version of the next release and not just the value of the\n     last, tagged commit.", 
            "title": "Version File"
        }, 
        {
            "location": "/dev-guide/release-process/", 
            "text": "Release Process\n\n\nHow to release libStorage\n\n\n\n\nProject Stages\n\n\nThis project has three parallels stages of release:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nunstable\n\n\nThe tip or HEAD of the \nmaster\n branch is referred to as \nunstable\n\n\n\n\n\n\nstaged\n\n\nA commit tagged with the suffix \n-rc\\d+\n such as \nv0.1.0-rc2\n is a \nstaged\n release. These are release candidates.\n\n\n\n\n\n\nstable\n\n\nA commit tagged with a version sans \n-rc\\d+\n suffix such as \nv0.1.0\n is a \nstable\n release.\n\n\n\n\n\n\n\n\nThere are no steps necessary to create an \nunstable\n release as that happens\nautomatically whenever an untagged commit is pushed to \nmaster\n. However, the\nfollowing workflow should be used when tagging a \nstaged\n release candidate\nor \nstable\n release.\n\n\n\n\nReview outstanding issues \n pull requests\n\n\nPrepare release notes\n\n\nUpdate the version file\n\n\nCommit \n pull request\n\n\nTag the release\n\n\nUpdate the version file (again)\n\n\n\n\nReview Issues \n Pull Requests\n\n\nThe first step to a release is to review the outstanding\n\nissues\n and\n\npull requests\n that are tagged\nfor the release in question.\n\n\nIf there are outstanding issues requiring changes or pending pull requests to\nbe merged, handle those prior to tagging any commit as a release candidate or\nrelease.\n\n\nIt is \nhighly\n recommended that pull requests be merged synchronously after\nrebasing each subsequent one off of the new tip of \nmaster\n. Remember, while\nGitHub will update a pull request as in conflict if a change to \nmaster\n\nresults in a merge conflict with the pull request, GitHub will \nnot\n force a\nnew build to spawn unless the pull request is actually updated.\n\n\nAt the very minimum a pull request's build should be re-executed prior to the\npull request being merged if \nmaster\n has changed since the pull request was\nopened.\n\n\nPrepare Release Notes\n\n\nUpdate the release notes at \n.docs/about/release-notes.md\n. This file is\nproject's authoritative changelog and should reflect new features, fixes, and\nany significant changes.\n\n\nThe most recent, \nstable\n version of the release notes are always available\nonline at\n\nlibStorage's documentation site\n.\n\n\nUpdate Version File\n\n\nThe \nVERSION\n file exists at the root of the project and should be updated to\nreflect the value of the intended release.\n\n\nFor example, if creating the first release candidate for version 0.1.0, the\ncontents of the \nVERSION\n file should be a single line \n0.1.0-rc1\n followed by\na newline character:\n\n\n$ cat VERSION\n0.1.0-rc1\n\n\n\n\nIf releasing version 0.1.0 proper then the contents of the \nVERSION\n file\nshould be \n0.1.0\n followed by a newline character:\n\n\n$ cat VERSION\n0.1.0\n\n\n\n\nCommit \n Pull Request\n\n\nOnce all outstanding issues and pull requests are handled, the release notes\nand version are updated, it's time to create a commit.\n\n\nPlease make sure that the changes to the release notes and version files are\na part of the same commit. This makes identifying the aspects of a release,\nstaged or otherwise, far easier for future developers.\n\n\nA release's commit message can either be a reflection of the release notes or\nsomething simple. Either way the commit message should have the following\nsubject format and first line in its body:\n\n\nRelease (Candidate) v0.1.0-rc1\n\nThis patch bumps the version to v0.1.0-rc1.\n\n\n\n\nIf the commit message is longer it should simply reflect the same information\nfrom the release notes.\n\n\nOnce committed push the change to a fork and open a pull request. Even though\nthis commit marks a staged or official release, the pull request system is still\nused to assure that the build completes successfully and there are no unforeseen\nerrors.\n\n\nTag the Release\n\n\nOnce the pull request marking the \nstaged\n or \nstable\n release has been merged\ninto \nupstream\n's \nmaster\n it's time to tag the release.\n\n\nTag Format\n\n\nThe release tag should follow a prescribed format depending upon the release\ntype:\n\n\n\n\n\n\n\n\nRelease Type\n\n\nTag Format\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nstaged\n\n\nvMAJOR.MINOR.PATCH-rc[0-9]\n\n\nv0.1.0-rc1\n\n\n\n\n\n\nstable\n\n\nvMAJOR.MINOR-PATCH\n\n\nv0.1.0\n\n\n\n\n\n\n\n\nTag Methods\n\n\nThere are two ways to tag a release:\n\n\n\n\nGitHub Releases\n\n\nCommand Line\n\n\n\n\nCommand Line\n\n\nIf tagging a release via the command line be sure to fetch the latest changes\nfrom \nupstream\n's \nmaster\n and either merge them into your local copy of\n\nmaster\n or reset the local copy to reflect \nupstream\n prior to creating\nany tags.\n\n\nThe following combination of commands can be used to create a tag for\n0.1.0 Release Candidate 1:\n\n\ngit fetch upstream \n \\\n  git checkout master \n \\\n  git reset --hard upstream/master \n \\\n  git tag -a -m v0.1.0-rc1 v0.1.0-rc1\n\n\n\n\nThe above example combines a few operations:\n\n\n\n\nThe first command fetches the \nupstream\n changes\n\n\nThe local \nmaster\n branch is checked out\n\n\nThe local \nmaster\n branch is hard reset to \nupstream/master\n\n\nAn annotated tag is created on \nmaster\n for \nv0.1.0-rc1\n, or 0.1.0 Release\n     Candidate 1, with a tag message of \nv0.1.0-rc1\n.\n\n\n\n\nPlease note that the third step will erase any changes that exist only in the\nlocal \nmaster\n branch that do not also exist in the remote, upstream copy.\nHowever, if the two branches are not equal this method should not be used to\ncreate a tag anyway.\n\n\nThe above steps do not actually push the tag upstream. This is to allow for one\nfinal review of all the changes before doing so since the appearance of a new,\nannotated tag in the repository will cause the project's build system to\nautomatically kick off a build that will result in the release of a \nstaged\n or\n\nstable\n release. For \nstable\n releases the project's documentation will also be\nupdated.\n\n\nOnce positive everything looks good simply execute the following command to\npush the tag to the \nupstream\n repository:\n\n\ngit push upstream v0.1.0-rc1\n\n\n\n\nUpdate Version File (Again)\n\n\nAfter a release is tagged there is one final step involving the \nVERSION\n file.\nThe contents of the file should be updated to reflect the next, targeted release\nso that the produced artifacts reflect the targeted version value and not a\nvalue based on the last, tagged commit.\n\n\nFollowing the above examples where version \nv0.1.0-rc1\n was just staged, the\n\nVERSION\n file should be updated to indicate that 0.1.0 Release Candidate 2\n(\n0.1.0-rc2\n) is the next, targeted release:\n\n\n$ cat VERSION\n0.1.0-rc2\n\n\n\n\nCommit the change to the \nVERSION\n file with a commit message similar to the\nfollowing:\n\n\nBumped active dev version to v0.1.0-rc2\n\nThis patch bumps the active dev version to v0.1.0-rc2.\n\n\n\n\nOnce the \nVERSION\n file change is committed, push the change and open a pull\nrequest to merge into the project.", 
            "title": "Release Process"
        }, 
        {
            "location": "/dev-guide/release-process/#release-process", 
            "text": "How to release libStorage", 
            "title": "Release Process"
        }, 
        {
            "location": "/dev-guide/release-process/#project-stages", 
            "text": "This project has three parallels stages of release:     Name  Description      unstable  The tip or HEAD of the  master  branch is referred to as  unstable    staged  A commit tagged with the suffix  -rc\\d+  such as  v0.1.0-rc2  is a  staged  release. These are release candidates.    stable  A commit tagged with a version sans  -rc\\d+  suffix such as  v0.1.0  is a  stable  release.     There are no steps necessary to create an  unstable  release as that happens\nautomatically whenever an untagged commit is pushed to  master . However, the\nfollowing workflow should be used when tagging a  staged  release candidate\nor  stable  release.   Review outstanding issues   pull requests  Prepare release notes  Update the version file  Commit   pull request  Tag the release  Update the version file (again)", 
            "title": "Project Stages"
        }, 
        {
            "location": "/dev-guide/release-process/#review-issues-pull-requests", 
            "text": "The first step to a release is to review the outstanding issues  and pull requests  that are tagged\nfor the release in question.  If there are outstanding issues requiring changes or pending pull requests to\nbe merged, handle those prior to tagging any commit as a release candidate or\nrelease.  It is  highly  recommended that pull requests be merged synchronously after\nrebasing each subsequent one off of the new tip of  master . Remember, while\nGitHub will update a pull request as in conflict if a change to  master \nresults in a merge conflict with the pull request, GitHub will  not  force a\nnew build to spawn unless the pull request is actually updated.  At the very minimum a pull request's build should be re-executed prior to the\npull request being merged if  master  has changed since the pull request was\nopened.", 
            "title": "Review Issues &amp; Pull Requests"
        }, 
        {
            "location": "/dev-guide/release-process/#prepare-release-notes", 
            "text": "Update the release notes at  .docs/about/release-notes.md . This file is\nproject's authoritative changelog and should reflect new features, fixes, and\nany significant changes.  The most recent,  stable  version of the release notes are always available\nonline at libStorage's documentation site .", 
            "title": "Prepare Release Notes"
        }, 
        {
            "location": "/dev-guide/release-process/#update-version-file", 
            "text": "The  VERSION  file exists at the root of the project and should be updated to\nreflect the value of the intended release.  For example, if creating the first release candidate for version 0.1.0, the\ncontents of the  VERSION  file should be a single line  0.1.0-rc1  followed by\na newline character:  $ cat VERSION\n0.1.0-rc1  If releasing version 0.1.0 proper then the contents of the  VERSION  file\nshould be  0.1.0  followed by a newline character:  $ cat VERSION\n0.1.0", 
            "title": "Update Version File"
        }, 
        {
            "location": "/dev-guide/release-process/#commit-pull-request", 
            "text": "Once all outstanding issues and pull requests are handled, the release notes\nand version are updated, it's time to create a commit.  Please make sure that the changes to the release notes and version files are\na part of the same commit. This makes identifying the aspects of a release,\nstaged or otherwise, far easier for future developers.  A release's commit message can either be a reflection of the release notes or\nsomething simple. Either way the commit message should have the following\nsubject format and first line in its body:  Release (Candidate) v0.1.0-rc1\n\nThis patch bumps the version to v0.1.0-rc1.  If the commit message is longer it should simply reflect the same information\nfrom the release notes.  Once committed push the change to a fork and open a pull request. Even though\nthis commit marks a staged or official release, the pull request system is still\nused to assure that the build completes successfully and there are no unforeseen\nerrors.", 
            "title": "Commit &amp; Pull Request"
        }, 
        {
            "location": "/dev-guide/release-process/#tag-the-release", 
            "text": "Once the pull request marking the  staged  or  stable  release has been merged\ninto  upstream 's  master  it's time to tag the release.", 
            "title": "Tag the Release"
        }, 
        {
            "location": "/dev-guide/release-process/#tag-format", 
            "text": "The release tag should follow a prescribed format depending upon the release\ntype:     Release Type  Tag Format  Example      staged  vMAJOR.MINOR.PATCH-rc[0-9]  v0.1.0-rc1    stable  vMAJOR.MINOR-PATCH  v0.1.0", 
            "title": "Tag Format"
        }, 
        {
            "location": "/dev-guide/release-process/#tag-methods", 
            "text": "There are two ways to tag a release:   GitHub Releases  Command Line", 
            "title": "Tag Methods"
        }, 
        {
            "location": "/dev-guide/release-process/#command-line", 
            "text": "If tagging a release via the command line be sure to fetch the latest changes\nfrom  upstream 's  master  and either merge them into your local copy of master  or reset the local copy to reflect  upstream  prior to creating\nany tags.  The following combination of commands can be used to create a tag for\n0.1.0 Release Candidate 1:  git fetch upstream   \\\n  git checkout master   \\\n  git reset --hard upstream/master   \\\n  git tag -a -m v0.1.0-rc1 v0.1.0-rc1  The above example combines a few operations:   The first command fetches the  upstream  changes  The local  master  branch is checked out  The local  master  branch is hard reset to  upstream/master  An annotated tag is created on  master  for  v0.1.0-rc1 , or 0.1.0 Release\n     Candidate 1, with a tag message of  v0.1.0-rc1 .   Please note that the third step will erase any changes that exist only in the\nlocal  master  branch that do not also exist in the remote, upstream copy.\nHowever, if the two branches are not equal this method should not be used to\ncreate a tag anyway.  The above steps do not actually push the tag upstream. This is to allow for one\nfinal review of all the changes before doing so since the appearance of a new,\nannotated tag in the repository will cause the project's build system to\nautomatically kick off a build that will result in the release of a  staged  or stable  release. For  stable  releases the project's documentation will also be\nupdated.  Once positive everything looks good simply execute the following command to\npush the tag to the  upstream  repository:  git push upstream v0.1.0-rc1", 
            "title": "Command Line"
        }, 
        {
            "location": "/dev-guide/release-process/#update-version-file-again", 
            "text": "After a release is tagged there is one final step involving the  VERSION  file.\nThe contents of the file should be updated to reflect the next, targeted release\nso that the produced artifacts reflect the targeted version value and not a\nvalue based on the last, tagged commit.  Following the above examples where version  v0.1.0-rc1  was just staged, the VERSION  file should be updated to indicate that 0.1.0 Release Candidate 2\n( 0.1.0-rc2 ) is the next, targeted release:  $ cat VERSION\n0.1.0-rc2  Commit the change to the  VERSION  file with a commit message similar to the\nfollowing:  Bumped active dev version to v0.1.0-rc2\n\nThis patch bumps the active dev version to v0.1.0-rc2.  Once the  VERSION  file change is committed, push the change and open a pull\nrequest to merge into the project.", 
            "title": "Update Version File (Again)"
        }, 
        {
            "location": "/about/contributing/", 
            "text": "Contributing to libStorage\n\n\nAn introduction to contributing to the libStorage project\n\n\n\n\nThe libStorage project welcomes, and depends, on contributions from developers\nand users in the open source community. Contributions can be made in a number of\nways, a few examples are:\n\n\n\n\nCode patches via pull requests\n\n\nDocumentation improvements\n\n\nBug reports and patch reviews\n\n\n\n\nReporting an Issue\n\n\nPlease include as much detail as you can. This includes:\n\n\n\n\nThe OS type and version\n\n\nThe libStorage commit\n\n\nThe storage system in question\n\n\nA set of logs with debug-logging enabled that show the problem\n\n\n\n\nSubmitting Pull Requests\n\n\nOnce you are happy with your changes or you are ready for some feedback, push\nit to your fork and send a pull request. For a change to be accepted it will\nmost likely need to have tests and documentation if it is a new feature.", 
            "title": "Contributing"
        }, 
        {
            "location": "/about/contributing/#contributing-to-libstorage", 
            "text": "An introduction to contributing to the libStorage project   The libStorage project welcomes, and depends, on contributions from developers\nand users in the open source community. Contributions can be made in a number of\nways, a few examples are:   Code patches via pull requests  Documentation improvements  Bug reports and patch reviews", 
            "title": "Contributing to libStorage"
        }, 
        {
            "location": "/about/contributing/#reporting-an-issue", 
            "text": "Please include as much detail as you can. This includes:   The OS type and version  The libStorage commit  The storage system in question  A set of logs with debug-logging enabled that show the problem", 
            "title": "Reporting an Issue"
        }, 
        {
            "location": "/about/contributing/#submitting-pull-requests", 
            "text": "Once you are happy with your changes or you are ready for some feedback, push\nit to your fork and send a pull request. For a change to be accepted it will\nmost likely need to have tests and documentation if it is a new feature.", 
            "title": "Submitting Pull Requests"
        }, 
        {
            "location": "/about/license/", 
            "text": "Licensing\n\n\nThe legal stuff\n\n\n\n\nlibStorage License\n\n\nLicensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use\nthis file except in compliance with the License. You may obtain a copy of the\nLicense at \nhttp://www.apache.org/licenses/LICENSE-2.0\n\n\nUnless required by applicable law or agreed to in writing, software distributed\nunder the License is distributed on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR\nCONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.", 
            "title": "License"
        }, 
        {
            "location": "/about/license/#licensing", 
            "text": "The legal stuff", 
            "title": "Licensing"
        }, 
        {
            "location": "/about/license/#libstorage-license", 
            "text": "Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use\nthis file except in compliance with the License. You may obtain a copy of the\nLicense at  http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed\nunder the License is distributed on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR\nCONDITIONS OF ANY KIND, either express or implied. See the License for the\nspecific language governing permissions and limitations under the License.", 
            "title": "libStorage License"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "Release Notes\n\n\nRelease early, release often\n\n\n\n\nVersion 0.2.0 (2016/09/07)\n\n\nBeginning with this release, libStorage's versions will increment the MINOR\ncomponent with the introduction of a new storage driver in concert with the\n\nguidelines\n set forth by semantic versioning.\n\n\nNew Features\n\n\n\n\nAmazon Elastic File System (EFS) Support (\n#231\n)\n\n\n\n\nEnhancements\n\n\n\n\nSupport for Go 1.7 (\n#251\n)\n\n\n\n\nBug Fixes\n\n\n\n\nIsilon Export Permissions (\n#252\n, \n#257\n)\n\n\nIsilon Volume Removal (\n#253\n)\n\n\n\n\nThank You\n\n\n\n\n\n\n\n\nName\n\n\nBlame\n\n\n\n\n\n\n\n\n\n\nChris Duchesne\n\n\nChris not only took on the role of project manager for libStorage and REX-Ray, he still provides ongoing test plan execution and release validation. Thank you Chris!\n\n\n\n\n\n\nKenny Cole\n\n\nKenny's tireless effort to support users and triage submitted issues is such a cornerstone to libStorage that I'm not sure what this project would do without him!\n\n\n\n\n\n\nMartin Hrabovcin\n\n\nMartin, along with Kasisnu, definitely win the \"Community Members of the Month\" award! Their hard work and dedication resulted in the introduction of the Amazon EFS storage driver. Thank you Martin \n Kasisnu!\n\n\n\n\n\n\nKasisnu Singh\n\n\nHave I mentioned we have the best community around? Seriously, thank you again Kasisnu! Your work, along with Martin's, is a milestone in the growth of libStorage.\n\n\n\n\n\n\n\n\nVersion 0.1.5 (2016/07/12)\n\n\nThis release comes hot on the heels of the last, but some dynamite bug fixes\nhave improved the performance of the server by leaps and bounds. Operations\nthat were taking minutes now take seconds or less. Memory consumption that\ncould exceed 50GB is now kept neat and tidy.\n\n\nBug Fixes\n\n\n\n\nTask service memory fix (\n#225\n)\n\n\nContext logger optimizations (\n#224\n)\n\n\n\n\nEnhancements\n\n\n\n\nImproved volume path caching (\n#227\n)\n\n\nMake Gometalinter optional (\n#223\n)\n\n\n\n\nVersion 0.1.4 (2016/07/08)\n\n\nThis update provides a major performance improvement as well as a few other,\nminor bug fixes and enhancements.\n\n\nBug Fixes\n\n\n\n\nPerformance degradation bug (\n#218\n)\n\n\nClose bug in ScaleIO driver (\n#213\n)\n\n\nPanic when checking attached instances with Isilon driver (\n#211\n)\n\n\n\n\nEnhancements\n\n\n\n\nImproved build process (\n#220\n)\n\n\nImproved executor logging (\n#217\n)\n\n\nLog timestamps in ms (\n#219\n)\n\n\nUpdated ScaleIO docs (\n#214\n)\n\n\n\n\nVersion 0.1.3 (2016/06/14)\n\n\nThis is a minor update to support the release of REX-Ray 0.4.0.\n\n\nEnhancements\n\n\n\n\nMarshal to YAML Enhancements (\n#203\n)\n\n\n\n\nVersion 0.1.2 (2016/06/13)\n\n\nThis release updates the default VirtualBox endpoint to \nhttp://10.0.2.2:18083\n.\n\n\nVersion 0.1.1 (2016/06/10)\n\n\nThis is the initial GA release of libStorage.\n\n\nFeatures\n\n\nlibStorage is an open source, platform agnostic, storage provisioning and\norchestration framework, model, and API. Features include:\n\n\n\n\nA standardized storage orchestration\n  \nmodel and API\n\n\nA lightweight, reference client implementation with a minimal dependency\n  footprint\n\n\nThe ability to embed both the libStorage client and server, creating native\n  application integration opportunities\n\n\n\n\nOperations\n\n\nlibStorage\n supports the following operations:\n\n\n\n\n\n\n\n\nResource Type\n\n\nOperation\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nVolume\n\n\nList / Inspect\n\n\nGet detailed information about one to many volumes\n\n\n\n\n\n\n\n\nCreate / Remote\n\n\nManage the volume lifecycle\n\n\n\n\n\n\n\n\nAttach / Detach\n\n\nProvision volumes to a client\n\n\n\n\n\n\n\n\nMount / Unmount\n\n\nMake attached volumes ready-to-use, local file systems\n\n\n\n\n\n\nSnapshot\n\n\n\n\nComing soon\n\n\n\n\n\n\nStorage Pool\n\n\n\n\nComing soon\n\n\n\n\n\n\n\n\nGetting Started\n\n\nUsing libStorage can be broken down into several, distinct steps:\n\n\n\n\nConfiguring \nlibStorage\n\n\nUnderstanding the \nAPI\n\n\nIdentifying a production server and client implementation, such as\n   \nREX-Ray\n\n\n\n\nThank You\n\n\n\n\n\n\n\n\nName\n\n\nBlame\n\n\n\n\n\n\n\n\n\n\nClint Kitson\n\n\nHis vision come to fruition. That's \nhis\n vision, thus please assign \nall\n bugs to Clint :)\n\n\n\n\n\n\nVladimir Vivien\n\n\nA nascent player, Vlad had to hit the ground running and has been a key contributor\n\n\n\n\n\n\nKenny Coleman\n\n\nWhile some come close, none are comparable to Kenny's handlebar\n\n\n\n\n\n\nJonas Rosland\n\n\nAlways good for a sanity check and keeping things on the straight and narrow\n\n\n\n\n\n\nSteph Carlson\n\n\nSteph keeps the convention train chugging along...\n\n\n\n\n\n\nAmanda Katona\n\n\nAnd Amanda is the one keeping the locomotive from going off the rails\n\n\n\n\n\n\nDrew Smith\n\n\nDrew is always ready to lend a hand, no matter the problem\n\n\n\n\n\n\nChris Duchesne\n\n\nHis short time with the team is in complete opposition to the value he has added to this project\n\n\n\n\n\n\nDavid vonThenen\n\n\nDavid has been a go-to guy for debugging the most difficult of issues\n\n\n\n\n\n\nSteve Wong\n\n\nSteve stays on top of the things and keeps use cases in sync with industry needs\n\n\n\n\n\n\nTravis Rhoden\n\n\nAnother keen mind, Travis is also a great font of technical know-how\n\n\n\n\n\n\nPeter Blum\n\n\nAbsent Peter, the EMC World demo would not have been ready\n\n\n\n\n\n\nMegan Hyland\n\n\nAnd absent Megan, Peter's work would only have taken things halfway there\n\n\n\n\n\n\nEugene Chupriyanov\n\n\nFor helping with the EC2 planning\n\n\n\n\n\n\nMatt Farina\n\n\nWithout Glide, it all comes crashing down\n\n\n\n\n\n\nJosh Bernstein\n\n\nThe shadowy figure behind the curtain...\n\n\n\n\n\n\n\n\nAnd many more...", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#release-notes", 
            "text": "Release early, release often", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/release-notes/#version-020-20160907", 
            "text": "Beginning with this release, libStorage's versions will increment the MINOR\ncomponent with the introduction of a new storage driver in concert with the guidelines  set forth by semantic versioning.", 
            "title": "Version 0.2.0 (2016/09/07)"
        }, 
        {
            "location": "/about/release-notes/#new-features", 
            "text": "Amazon Elastic File System (EFS) Support ( #231 )", 
            "title": "New Features"
        }, 
        {
            "location": "/about/release-notes/#enhancements", 
            "text": "Support for Go 1.7 ( #251 )", 
            "title": "Enhancements"
        }, 
        {
            "location": "/about/release-notes/#bug-fixes", 
            "text": "Isilon Export Permissions ( #252 ,  #257 )  Isilon Volume Removal ( #253 )", 
            "title": "Bug Fixes"
        }, 
        {
            "location": "/about/release-notes/#thank-you", 
            "text": "Name  Blame      Chris Duchesne  Chris not only took on the role of project manager for libStorage and REX-Ray, he still provides ongoing test plan execution and release validation. Thank you Chris!    Kenny Cole  Kenny's tireless effort to support users and triage submitted issues is such a cornerstone to libStorage that I'm not sure what this project would do without him!    Martin Hrabovcin  Martin, along with Kasisnu, definitely win the \"Community Members of the Month\" award! Their hard work and dedication resulted in the introduction of the Amazon EFS storage driver. Thank you Martin   Kasisnu!    Kasisnu Singh  Have I mentioned we have the best community around? Seriously, thank you again Kasisnu! Your work, along with Martin's, is a milestone in the growth of libStorage.", 
            "title": "Thank You"
        }, 
        {
            "location": "/about/release-notes/#version-015-20160712", 
            "text": "This release comes hot on the heels of the last, but some dynamite bug fixes\nhave improved the performance of the server by leaps and bounds. Operations\nthat were taking minutes now take seconds or less. Memory consumption that\ncould exceed 50GB is now kept neat and tidy.", 
            "title": "Version 0.1.5 (2016/07/12)"
        }, 
        {
            "location": "/about/release-notes/#bug-fixes_1", 
            "text": "Task service memory fix ( #225 )  Context logger optimizations ( #224 )", 
            "title": "Bug Fixes"
        }, 
        {
            "location": "/about/release-notes/#enhancements_1", 
            "text": "Improved volume path caching ( #227 )  Make Gometalinter optional ( #223 )", 
            "title": "Enhancements"
        }, 
        {
            "location": "/about/release-notes/#version-014-20160708", 
            "text": "This update provides a major performance improvement as well as a few other,\nminor bug fixes and enhancements.", 
            "title": "Version 0.1.4 (2016/07/08)"
        }, 
        {
            "location": "/about/release-notes/#bug-fixes_2", 
            "text": "Performance degradation bug ( #218 )  Close bug in ScaleIO driver ( #213 )  Panic when checking attached instances with Isilon driver ( #211 )", 
            "title": "Bug Fixes"
        }, 
        {
            "location": "/about/release-notes/#enhancements_2", 
            "text": "Improved build process ( #220 )  Improved executor logging ( #217 )  Log timestamps in ms ( #219 )  Updated ScaleIO docs ( #214 )", 
            "title": "Enhancements"
        }, 
        {
            "location": "/about/release-notes/#version-013-20160614", 
            "text": "This is a minor update to support the release of REX-Ray 0.4.0.", 
            "title": "Version 0.1.3 (2016/06/14)"
        }, 
        {
            "location": "/about/release-notes/#enhancements_3", 
            "text": "Marshal to YAML Enhancements ( #203 )", 
            "title": "Enhancements"
        }, 
        {
            "location": "/about/release-notes/#version-012-20160613", 
            "text": "This release updates the default VirtualBox endpoint to  http://10.0.2.2:18083 .", 
            "title": "Version 0.1.2 (2016/06/13)"
        }, 
        {
            "location": "/about/release-notes/#version-011-20160610", 
            "text": "This is the initial GA release of libStorage.", 
            "title": "Version 0.1.1 (2016/06/10)"
        }, 
        {
            "location": "/about/release-notes/#features", 
            "text": "libStorage is an open source, platform agnostic, storage provisioning and\norchestration framework, model, and API. Features include:   A standardized storage orchestration\n   model and API  A lightweight, reference client implementation with a minimal dependency\n  footprint  The ability to embed both the libStorage client and server, creating native\n  application integration opportunities", 
            "title": "Features"
        }, 
        {
            "location": "/about/release-notes/#operations", 
            "text": "libStorage  supports the following operations:     Resource Type  Operation  Description      Volume  List / Inspect  Get detailed information about one to many volumes     Create / Remote  Manage the volume lifecycle     Attach / Detach  Provision volumes to a client     Mount / Unmount  Make attached volumes ready-to-use, local file systems    Snapshot   Coming soon    Storage Pool   Coming soon", 
            "title": "Operations"
        }, 
        {
            "location": "/about/release-notes/#getting-started", 
            "text": "Using libStorage can be broken down into several, distinct steps:   Configuring  libStorage  Understanding the  API  Identifying a production server and client implementation, such as\n    REX-Ray", 
            "title": "Getting Started"
        }, 
        {
            "location": "/about/release-notes/#thank-you_1", 
            "text": "Name  Blame      Clint Kitson  His vision come to fruition. That's  his  vision, thus please assign  all  bugs to Clint :)    Vladimir Vivien  A nascent player, Vlad had to hit the ground running and has been a key contributor    Kenny Coleman  While some come close, none are comparable to Kenny's handlebar    Jonas Rosland  Always good for a sanity check and keeping things on the straight and narrow    Steph Carlson  Steph keeps the convention train chugging along...    Amanda Katona  And Amanda is the one keeping the locomotive from going off the rails    Drew Smith  Drew is always ready to lend a hand, no matter the problem    Chris Duchesne  His short time with the team is in complete opposition to the value he has added to this project    David vonThenen  David has been a go-to guy for debugging the most difficult of issues    Steve Wong  Steve stays on top of the things and keeps use cases in sync with industry needs    Travis Rhoden  Another keen mind, Travis is also a great font of technical know-how    Peter Blum  Absent Peter, the EMC World demo would not have been ready    Megan Hyland  And absent Megan, Peter's work would only have taken things halfway there    Eugene Chupriyanov  For helping with the EC2 planning    Matt Farina  Without Glide, it all comes crashing down    Josh Bernstein  The shadowy figure behind the curtain...     And many more...", 
            "title": "Thank You"
        }
    ]
}